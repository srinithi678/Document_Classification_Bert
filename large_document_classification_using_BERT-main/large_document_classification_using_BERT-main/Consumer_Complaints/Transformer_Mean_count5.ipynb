{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Transformer_Mean_count5_Testdata_dc.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "LUgSWzLG3JWF"
      },
      "source": [
        "# # # cheking the number of cored this system has.\n",
        "# !cat /proc/cpuinfo | grep \"cpu cores\" | uniq\n",
        "\n",
        "# # GPU info\n",
        "# !nvidia-smi\n",
        "\n",
        "# # Amount of system RAM available to be used.\n",
        "# from psutil import virtual_memory\n",
        "# ram_gb = virtual_memory().total / (1024 * 1024 * 1024)   \n",
        "# print('Your runtime has {:.1f} gigabyte of availabe\\n'.format(ram_gb))\n",
        "\n",
        "# #finding the recursion limit to avoid Augmentation recursion error \n",
        "# import sys\n",
        "# print(sys.getrecursionlimit())\n",
        "\n",
        "# #installing fastai\n",
        "# !pip install torch===1.4.0 torchvision===0.5.0 -f https://download.pytorch.org/whl/torch_stable.html"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5KF0pKp93cni",
        "outputId": "327c209b-99e0-4530-ec08-12480703ba9c"
      },
      "source": [
        "#importing libraries and initializing fastai \n",
        "import pandas as pd \n",
        "import numpy as np \n",
        "import time\n",
        "\n",
        "#Mounting google drive for saving the models after training \n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "from fastai.vision import *\n",
        "from fastai.metrics import error_rate"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "DU9_FNMe5US1",
        "outputId": "687e3835-fba0-4b2f-8970-f5749f00c48d"
      },
      "source": [
        "#loading the data \n",
        "#There are NaN values in the consumer_complaint_narrative column\n",
        "train_raw = pd.read_csv('/content/drive/MyDrive/MS_Final_Project/Dataset_Ref/consumer_complaints.csv')\n",
        "train_raw.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (5,11) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date_received</th>\n",
              "      <th>product</th>\n",
              "      <th>sub_product</th>\n",
              "      <th>issue</th>\n",
              "      <th>sub_issue</th>\n",
              "      <th>consumer_complaint_narrative</th>\n",
              "      <th>company_public_response</th>\n",
              "      <th>company</th>\n",
              "      <th>state</th>\n",
              "      <th>zipcode</th>\n",
              "      <th>tags</th>\n",
              "      <th>consumer_consent_provided</th>\n",
              "      <th>submitted_via</th>\n",
              "      <th>date_sent_to_company</th>\n",
              "      <th>company_response_to_consumer</th>\n",
              "      <th>timely_response</th>\n",
              "      <th>consumer_disputed?</th>\n",
              "      <th>complaint_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>08/30/2013</td>\n",
              "      <td>Mortgage</td>\n",
              "      <td>Other mortgage</td>\n",
              "      <td>Loan modification,collection,foreclosure</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>U.S. Bancorp</td>\n",
              "      <td>CA</td>\n",
              "      <td>95993</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Referral</td>\n",
              "      <td>09/03/2013</td>\n",
              "      <td>Closed with explanation</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>511074</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>08/30/2013</td>\n",
              "      <td>Mortgage</td>\n",
              "      <td>Other mortgage</td>\n",
              "      <td>Loan servicing, payments, escrow account</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Wells Fargo &amp; Company</td>\n",
              "      <td>CA</td>\n",
              "      <td>91104</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Referral</td>\n",
              "      <td>09/03/2013</td>\n",
              "      <td>Closed with explanation</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>511080</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>08/30/2013</td>\n",
              "      <td>Credit reporting</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Incorrect information on credit report</td>\n",
              "      <td>Account status</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Wells Fargo &amp; Company</td>\n",
              "      <td>NY</td>\n",
              "      <td>11764</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Postal mail</td>\n",
              "      <td>09/18/2013</td>\n",
              "      <td>Closed with explanation</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>510473</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>08/30/2013</td>\n",
              "      <td>Student loan</td>\n",
              "      <td>Non-federal student loan</td>\n",
              "      <td>Repaying your loan</td>\n",
              "      <td>Repaying your loan</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Navient Solutions, Inc.</td>\n",
              "      <td>MD</td>\n",
              "      <td>21402</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Email</td>\n",
              "      <td>08/30/2013</td>\n",
              "      <td>Closed with explanation</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>510326</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>08/30/2013</td>\n",
              "      <td>Debt collection</td>\n",
              "      <td>Credit card</td>\n",
              "      <td>False statements or representation</td>\n",
              "      <td>Attempted to collect wrong amount</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Resurgent Capital Services L.P.</td>\n",
              "      <td>GA</td>\n",
              "      <td>30106</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Web</td>\n",
              "      <td>08/30/2013</td>\n",
              "      <td>Closed with explanation</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>511067</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  date_received           product  ... consumer_disputed? complaint_id\n",
              "0    08/30/2013          Mortgage  ...                Yes       511074\n",
              "1    08/30/2013          Mortgage  ...                Yes       511080\n",
              "2    08/30/2013  Credit reporting  ...                 No       510473\n",
              "3    08/30/2013      Student loan  ...                Yes       510326\n",
              "4    08/30/2013   Debt collection  ...                Yes       511067\n",
              "\n",
              "[5 rows x 18 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aP3sg9DF5UVi",
        "outputId": "bda79488-f6e2-4619-bab3-b23a0959bbcc"
      },
      "source": [
        "#Training data shape\n",
        "train_raw.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(555957, 18)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jr-vmJ_g5UYE",
        "outputId": "af5dbe91-9940-4994-8327-535d3d3571a5"
      },
      "source": [
        "#Preprocessing the data \n",
        "#Extracting only those data whose consumer_complaint_narrative column is not null\n",
        "#columns = 18\n",
        "train_raw = train_raw[train_raw.consumer_complaint_narrative.notnull()]\n",
        "train_raw.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(66806, 18)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "d8AXktCu6dhX",
        "outputId": "e88fa5e4-5666-4f5b-c9c2-514851015307"
      },
      "source": [
        "#It splits the string into , separated values \n",
        "train_raw.consumer_complaint_narrative.apply(lambda x:len(x.split())).plot(kind='hist')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fbb316def90>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lvN3HgfKCXlC"
      },
      "source": [
        "train_raw['len_txt'] =train_raw.consumer_complaint_narrative.apply(lambda x: len(x.split()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "4NHjucCRCeCS",
        "outputId": "8ab36759-2dcc-4ca9-d32d-accb7c229cbc"
      },
      "source": [
        "train_raw.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>complaint_id</th>\n",
              "      <th>len_txt</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>6.680600e+04</td>\n",
              "      <td>66806.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>1.571665e+06</td>\n",
              "      <td>190.644014</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.545692e+05</td>\n",
              "      <td>166.830597</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.290181e+06</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>1.443264e+06</td>\n",
              "      <td>71.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>1.569485e+06</td>\n",
              "      <td>136.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1.702750e+06</td>\n",
              "      <td>254.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.888608e+06</td>\n",
              "      <td>1284.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       complaint_id       len_txt\n",
              "count  6.680600e+04  66806.000000\n",
              "mean   1.571665e+06    190.644014\n",
              "std    1.545692e+05    166.830597\n",
              "min    1.290181e+06      1.000000\n",
              "25%    1.443264e+06     71.000000\n",
              "50%    1.569485e+06    136.000000\n",
              "75%    1.702750e+06    254.000000\n",
              "max    1.888608e+06   1284.000000"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OBEkUA71PMLB",
        "outputId": "4e89d85a-ae9e-4f14-caad-100491901f70"
      },
      "source": [
        "train_raw.columns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['date_received', 'product', 'sub_product', 'issue', 'sub_issue',\n",
              "       'consumer_complaint_narrative', 'company_public_response', 'company',\n",
              "       'state', 'zipcode', 'tags', 'consumer_consent_provided',\n",
              "       'submitted_via', 'date_sent_to_company', 'company_response_to_consumer',\n",
              "       'timely_response', 'consumer_disputed?', 'complaint_id', 'len_txt'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M1CTdhCLCiL6",
        "outputId": "16f90351-01a7-44ce-8988-5fed46eeb53a"
      },
      "source": [
        "train_raw.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(66806, 19)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BrjaAw55ms5q",
        "outputId": "ad81bbb2-5479-45bd-a2b4-5cda818b0cb0"
      },
      "source": [
        "#Select only the rows with more than 250 words \n",
        "train_raw = train_raw[train_raw.len_txt >249]\n",
        "train_raw.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(17142, 19)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "id": "aADLdVkGPjYi",
        "outputId": "2a5af5c2-59b3-4355-90a9-c5e271ab285a"
      },
      "source": [
        "train_raw.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date_received</th>\n",
              "      <th>product</th>\n",
              "      <th>sub_product</th>\n",
              "      <th>issue</th>\n",
              "      <th>sub_issue</th>\n",
              "      <th>consumer_complaint_narrative</th>\n",
              "      <th>company_public_response</th>\n",
              "      <th>company</th>\n",
              "      <th>state</th>\n",
              "      <th>zipcode</th>\n",
              "      <th>tags</th>\n",
              "      <th>consumer_consent_provided</th>\n",
              "      <th>submitted_via</th>\n",
              "      <th>date_sent_to_company</th>\n",
              "      <th>company_response_to_consumer</th>\n",
              "      <th>timely_response</th>\n",
              "      <th>consumer_disputed?</th>\n",
              "      <th>complaint_id</th>\n",
              "      <th>len_txt</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>190155</th>\n",
              "      <td>03/19/2015</td>\n",
              "      <td>Mortgage</td>\n",
              "      <td>Conventional fixed mortgage</td>\n",
              "      <td>Loan modification,collection,foreclosure</td>\n",
              "      <td>NaN</td>\n",
              "      <td>In XX/XX/XXXX my wages that I earned at my job...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Wells Fargo &amp; Company</td>\n",
              "      <td>CA</td>\n",
              "      <td>946XX</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Consent provided</td>\n",
              "      <td>Web</td>\n",
              "      <td>03/19/2015</td>\n",
              "      <td>Closed with explanation</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>1290524</td>\n",
              "      <td>666</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>190208</th>\n",
              "      <td>03/19/2015</td>\n",
              "      <td>Mortgage</td>\n",
              "      <td>Conventional fixed mortgage</td>\n",
              "      <td>Credit decision / Underwriting</td>\n",
              "      <td>NaN</td>\n",
              "      <td>XXXX was submitted XX/XX/XXXX. At the time I s...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Rushmore Loan Management Services LLC</td>\n",
              "      <td>CA</td>\n",
              "      <td>956XX</td>\n",
              "      <td>Older American</td>\n",
              "      <td>Consent provided</td>\n",
              "      <td>Web</td>\n",
              "      <td>03/19/2015</td>\n",
              "      <td>Closed with explanation</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>1292137</td>\n",
              "      <td>259</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>190251</th>\n",
              "      <td>03/19/2015</td>\n",
              "      <td>Mortgage</td>\n",
              "      <td>Conventional fixed mortgage</td>\n",
              "      <td>Loan servicing, payments, escrow account</td>\n",
              "      <td>NaN</td>\n",
              "      <td>I spoke to XXXX of green tree representatives ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Ditech Financial LLC</td>\n",
              "      <td>CA</td>\n",
              "      <td>948XX</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Consent provided</td>\n",
              "      <td>Web</td>\n",
              "      <td>03/19/2015</td>\n",
              "      <td>Closed with non-monetary relief</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>1290534</td>\n",
              "      <td>301</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>190263</th>\n",
              "      <td>03/19/2015</td>\n",
              "      <td>Credit card</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Other</td>\n",
              "      <td>NaN</td>\n",
              "      <td>i opened XXXX Bank of America credit cards 15-...</td>\n",
              "      <td>Company chooses not to provide a public response</td>\n",
              "      <td>Bank of America</td>\n",
              "      <td>OR</td>\n",
              "      <td>971XX</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Consent provided</td>\n",
              "      <td>Web</td>\n",
              "      <td>03/19/2015</td>\n",
              "      <td>Closed with monetary relief</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>1292209</td>\n",
              "      <td>780</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>190264</th>\n",
              "      <td>03/19/2015</td>\n",
              "      <td>Consumer Loan</td>\n",
              "      <td>Vehicle loan</td>\n",
              "      <td>Taking out the loan or lease</td>\n",
              "      <td>NaN</td>\n",
              "      <td>I applied for a loan with XXXX XXXX and had pu...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Hyundai Capital America</td>\n",
              "      <td>MS</td>\n",
              "      <td>392XX</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Consent provided</td>\n",
              "      <td>Web</td>\n",
              "      <td>03/19/2015</td>\n",
              "      <td>Closed with explanation</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>1292159</td>\n",
              "      <td>558</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       date_received        product  ... complaint_id len_txt\n",
              "190155    03/19/2015       Mortgage  ...      1290524     666\n",
              "190208    03/19/2015       Mortgage  ...      1292137     259\n",
              "190251    03/19/2015       Mortgage  ...      1290534     301\n",
              "190263    03/19/2015    Credit card  ...      1292209     780\n",
              "190264    03/19/2015  Consumer Loan  ...      1292159     558\n",
              "\n",
              "[5 rows x 19 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "mJ2aeLKnmtQ1",
        "outputId": "fe6b09a8-137e-4d60-cf69-98b1a7804ca5"
      },
      "source": [
        "#selecting only the consumer_complaint_narrative and product columns\n",
        "train_raw=train_raw[['consumer_complaint_narrative','product']]\n",
        "train_raw.reset_index(inplace=True, drop=True)\n",
        "train_raw.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>consumer_complaint_narrative</th>\n",
              "      <th>product</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>In XX/XX/XXXX my wages that I earned at my job...</td>\n",
              "      <td>Mortgage</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>XXXX was submitted XX/XX/XXXX. At the time I s...</td>\n",
              "      <td>Mortgage</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I spoke to XXXX of green tree representatives ...</td>\n",
              "      <td>Mortgage</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>i opened XXXX Bank of America credit cards 15-...</td>\n",
              "      <td>Credit card</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I applied for a loan with XXXX XXXX and had pu...</td>\n",
              "      <td>Consumer Loan</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                        consumer_complaint_narrative        product\n",
              "0  In XX/XX/XXXX my wages that I earned at my job...       Mortgage\n",
              "1  XXXX was submitted XX/XX/XXXX. At the time I s...       Mortgage\n",
              "2  I spoke to XXXX of green tree representatives ...       Mortgage\n",
              "3  i opened XXXX Bank of America credit cards 15-...    Credit card\n",
              "4  I applied for a loan with XXXX XXXX and had pu...  Consumer Loan"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jsevf5_fmtTv",
        "outputId": "e2ef51a7-f870-4047-c746-9cac286bf73d"
      },
      "source": [
        "train_raw['product'].unique()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Mortgage', 'Credit card', 'Consumer Loan', 'Debt collection', 'Credit reporting', 'Student loan',\n",
              "       'Bank account or service', 'Money transfers', 'Payday loan', 'Prepaid card', 'Other financial service'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "jm4c126BmtW7",
        "outputId": "154dfc71-0665-42c7-ed29-3ad42be2e36d"
      },
      "source": [
        "#group similar products  dataframe.at = accessing a value using row column pair \n",
        "train_raw.at[train_raw['product']=='Credit reporting','product']= 'Credit reporting, credit repair services, or other personal consumer reports'\n",
        "train_raw.at[train_raw['product'] == 'Credit card', 'product'] = 'Credit card or prepaid card'\n",
        "train_raw.at[train_raw['product'] == 'Prepaid card', 'product'] = 'Credit card or prepaid card'\n",
        "train_raw.at[train_raw['product'] == 'Payday loan', 'product'] = 'Payday loan, title loan, or personal loan'\n",
        "train_raw.at[train_raw['product'] == 'Virtual currency', 'product'] = 'Money transfer, virtual currency, or money service'\n",
        "train_raw.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>consumer_complaint_narrative</th>\n",
              "      <th>product</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>In XX/XX/XXXX my wages that I earned at my job...</td>\n",
              "      <td>Mortgage</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>XXXX was submitted XX/XX/XXXX. At the time I s...</td>\n",
              "      <td>Mortgage</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I spoke to XXXX of green tree representatives ...</td>\n",
              "      <td>Mortgage</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>i opened XXXX Bank of America credit cards 15-...</td>\n",
              "      <td>Credit card or prepaid card</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I applied for a loan with XXXX XXXX and had pu...</td>\n",
              "      <td>Consumer Loan</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                        consumer_complaint_narrative                      product\n",
              "0  In XX/XX/XXXX my wages that I earned at my job...                     Mortgage\n",
              "1  XXXX was submitted XX/XX/XXXX. At the time I s...                     Mortgage\n",
              "2  I spoke to XXXX of green tree representatives ...                     Mortgage\n",
              "3  i opened XXXX Bank of America credit cards 15-...  Credit card or prepaid card\n",
              "4  I applied for a loan with XXXX XXXX and had pu...                Consumer Loan"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OZdxoRt5mtaH",
        "outputId": "c86d6fa7-db7e-4dfa-c3dd-524565037a41"
      },
      "source": [
        "train_raw['product'].unique()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Mortgage', 'Credit card or prepaid card', 'Consumer Loan', 'Debt collection',\n",
              "       'Credit reporting, credit repair services, or other personal consumer reports', 'Student loan',\n",
              "       'Bank account or service', 'Money transfers', 'Payday loan, title loan, or personal loan',\n",
              "       'Other financial service'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "znSJSyJuqCDk",
        "outputId": "a22167c9-8be3-4621-ddef-8bb67ee1539e"
      },
      "source": [
        "train_raw['product'].value_counts().sort_values(ascending=False).plot(kind='bar')\n",
        "#unbalanced dataset "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fbb3118ead0>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "K1E6q3i6qMPw",
        "outputId": "47fd4859-dd18-4223-8883-17b6c1a7c073"
      },
      "source": [
        "#Renaming the columns \n",
        "train_raw=train_raw.rename(columns = {'consumer_complaint_narrative':'text', 'product':'label'})\n",
        "train_raw.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>In XX/XX/XXXX my wages that I earned at my job...</td>\n",
              "      <td>Mortgage</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>XXXX was submitted XX/XX/XXXX. At the time I s...</td>\n",
              "      <td>Mortgage</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I spoke to XXXX of green tree representatives ...</td>\n",
              "      <td>Mortgage</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>i opened XXXX Bank of America credit cards 15-...</td>\n",
              "      <td>Credit card or prepaid card</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I applied for a loan with XXXX XXXX and had pu...</td>\n",
              "      <td>Consumer Loan</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text                        label\n",
              "0  In XX/XX/XXXX my wages that I earned at my job...                     Mortgage\n",
              "1  XXXX was submitted XX/XX/XXXX. At the time I s...                     Mortgage\n",
              "2  I spoke to XXXX of green tree representatives ...                     Mortgage\n",
              "3  i opened XXXX Bank of America credit cards 15-...  Credit card or prepaid card\n",
              "4  I applied for a loan with XXXX XXXX and had pu...                Consumer Loan"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "ffaa3mq3qZu5",
        "outputId": "f6619dcc-50c5-4566-b9bd-be8e8d93901b"
      },
      "source": [
        "#changing the categorical value column to integers\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "LE = LabelEncoder()\n",
        "train_raw['label'] = LE.fit_transform(train_raw['label'])\n",
        "train_raw.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>In XX/XX/XXXX my wages that I earned at my job...</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>XXXX was submitted XX/XX/XXXX. At the time I s...</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I spoke to XXXX of green tree representatives ...</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>i opened XXXX Bank of America credit cards 15-...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I applied for a loan with XXXX XXXX and had pu...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  label\n",
              "0  In XX/XX/XXXX my wages that I earned at my job...      6\n",
              "1  XXXX was submitted XX/XX/XXXX. At the time I s...      6\n",
              "2  I spoke to XXXX of green tree representatives ...      6\n",
              "3  i opened XXXX Bank of America credit cards 15-...      2\n",
              "4  I applied for a loan with XXXX XXXX and had pu...      1"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tHif9iOMq4Tc",
        "outputId": "498a0057-396c-4115-fe2c-cbf4204eea0f"
      },
      "source": [
        "len(np.unique(train_raw['label']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygzKXiBkq7Qq"
      },
      "source": [
        "#creating the copy of the dataframe\n",
        "#dataframe.copy(deep=True)  ==> This will create a copy and any changes to the copy will not be reflected in the original df\n",
        "train = train_raw.copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "uLDeNP3mrhby",
        "outputId": "df382c41-c345-4863-a6cf-b7bc89b1aea2"
      },
      "source": [
        "#reindexing to create randomness \n",
        "train = train.reindex(np.random.permutation(train.index))\n",
        "train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>9680</th>\n",
              "      <td>My wife and I went to Huntington Bank, applied...</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15741</th>\n",
              "      <td>I disputed fraudulent charges on my credit car...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15554</th>\n",
              "      <td>To Whom It May Concern, Here is a summary of e...</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10650</th>\n",
              "      <td>Upon reviewing my Bank of America checking acc...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15076</th>\n",
              "      <td>On Tuesday XXXX XXXX I spoke with a representa...</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    text  label\n",
              "9680   My wife and I went to Huntington Bank, applied...      6\n",
              "15741  I disputed fraudulent charges on my credit car...      2\n",
              "15554  To Whom It May Concern, Here is a summary of e...      6\n",
              "10650  Upon reviewing my Bank of America checking acc...      0\n",
              "15076  On Tuesday XXXX XXXX I spoke with a representa...      6"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fLH4GcrFrqF5"
      },
      "source": [
        "#remove the non-alphanumeric characters from the text \n",
        "import re \n",
        "def clean_txt(text):\n",
        "  text = re.sub(\"'\", \"\",text)\n",
        "  text=re.sub(\"(\\\\W)+\",\" \",text)     #() -- to match the sequence inside it , \\-- to escape the special characters , \n",
        "                                     #\\W -- get all the nonalphanumeric characters, + --all the instances \n",
        "\n",
        "  return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "4Vbl1bJHuRZO",
        "outputId": "02ed74e7-b26c-432c-a848-e57a27fd0ee1"
      },
      "source": [
        "train['text']  = train.text.apply(clean_txt)\n",
        "train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>9680</th>\n",
              "      <td>My wife and I went to Huntington Bank applied ...</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15741</th>\n",
              "      <td>I disputed fraudulent charges on my credit car...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15554</th>\n",
              "      <td>To Whom It May Concern Here is a summary of ev...</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10650</th>\n",
              "      <td>Upon reviewing my Bank of America checking acc...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15076</th>\n",
              "      <td>On Tuesday XXXX XXXX I spoke with a representa...</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    text  label\n",
              "9680   My wife and I went to Huntington Bank applied ...      6\n",
              "15741  I disputed fraudulent charges on my credit car...      2\n",
              "15554  To Whom It May Concern Here is a summary of ev...      6\n",
              "10650  Upon reviewing my Bank of America checking acc...      0\n",
              "15076  On Tuesday XXXX XXXX I spoke with a representa...      6"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "id": "70JSI0FzuhvN",
        "outputId": "8bce2b46-3b3e-458d-ec13-994f989dd9a8"
      },
      "source": [
        "train.reset_index(drop=True, inplace=True)\n",
        "train.head(2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>My wife and I went to Huntington Bank applied ...</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I disputed fraudulent charges on my credit car...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  label\n",
              "0  My wife and I went to Huntington Bank applied ...      6\n",
              "1  I disputed fraudulent charges on my credit car...      2"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sPFrymvmUxrC",
        "outputId": "fd4373cd-9e5a-4b80-83df-9f6c6fd86c3b"
      },
      "source": [
        "train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(17142, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vzNmHwVkuijj"
      },
      "source": [
        "# val.reset_index(drop=True, inplace=True)\n",
        "# val.head(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_sCe_oevuy1"
      },
      "source": [
        "# val.shape, train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TOJO40hlz7Xp",
        "outputId": "365a9593-07e0-43bf-fe02-18c7ebd72b61"
      },
      "source": [
        "!pip install tensorflow==2.5.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow==2.5.0 in /usr/local/lib/python3.7/dist-packages (2.5.0)\n",
            "Requirement already satisfied: keras-nightly~=2.5.0.dev in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0) (2.5.0.dev2021032900)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0) (1.12)\n",
            "Requirement already satisfied: tensorflow-estimator<2.6.0,>=2.5.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0) (3.7.4.3)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0) (0.12.0)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0) (1.1.0)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0) (3.3.0)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0) (1.12.1)\n",
            "Requirement already satisfied: grpcio~=1.34.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0) (1.34.1)\n",
            "Requirement already satisfied: h5py~=3.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0) (3.1.0)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0) (0.2.0)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0) (0.37.0)\n",
            "Requirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0) (1.19.5)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0) (1.1.2)\n",
            "Requirement already satisfied: tensorboard~=2.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0) (2.6.0)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0) (1.15.0)\n",
            "Requirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0) (0.4.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0) (3.17.3)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5.0) (1.6.3)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py~=3.1.0->tensorflow==2.5.0) (1.5.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow==2.5.0) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow==2.5.0) (0.6.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow==2.5.0) (57.4.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow==2.5.0) (3.3.4)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow==2.5.0) (1.8.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow==2.5.0) (0.4.6)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow==2.5.0) (1.35.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow==2.5.0) (2.23.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow==2.5.0) (4.7.2)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow==2.5.0) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow==2.5.0) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow==2.5.0) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.5->tensorflow==2.5.0) (4.8.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow==2.5.0) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow==2.5.0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow==2.5.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow==2.5.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow==2.5.0) (2021.5.30)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow==2.5.0) (3.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard~=2.5->tensorflow==2.5.0) (3.6.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5EVcradUvyW5",
        "outputId": "6f6af355-dd96-4446-d377-099ec43172f5"
      },
      "source": [
        "#Installing the BERT module\n",
        "!pip install bert-tensorflow\n",
        "#!pip install bert-for-tf2\n",
        "\n",
        "import bert\n",
        "from bert import optimization\n",
        "\n",
        "!pip install -q tf-models-official==2.4.0\n",
        "\n",
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_datasets as tfds\n",
        "tfds.disable_progress_bar()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: bert-tensorflow in /usr/local/lib/python3.7/dist-packages (1.0.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from bert-tensorflow) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2IxzeWXGz_YE",
        "outputId": "33cb74e3-bcbc-46dd-ca57-894a88d6440d"
      },
      "source": [
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IaasMDd0Pn3P"
      },
      "source": [
        "\n",
        "# Setting The Output Directory for BERT\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2XEgt457yd_0",
        "outputId": "8b8d83cc-b091-48a4-da55-9bfdd3bb3d24"
      },
      "source": [
        "#Setting the output directory for BERT \n",
        "# Set the output directory for saving model file\n",
        "OUTPUT_DIR = '/content/drive/MyDrive/MS_Final_Project/Model_checkpoints_CC'\n",
        "\n",
        "#@markdown Whether or not to clear/delete the directory and create a new one\n",
        "DO_DELETE = True #@param {type:\"boolean\"}\n",
        "\n",
        "if DO_DELETE:\n",
        "  try:\n",
        "    tf.io.gfile.DeleteRecursively(OUTPUT_DIR)#deletes everything under the directory recursively\n",
        "  except:\n",
        "    pass\n",
        "\n",
        "tf.io.gfile.makedirs(OUTPUT_DIR) #Creates a directory and all parent/intermediate directories.\n",
        "print('***** Model output directory: {} *****'.format(OUTPUT_DIR))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "***** Model output directory: /content/drive/MyDrive/MS_Final_Project/Model_checkpoints_CC *****\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OP59yHEBy7Pk",
        "outputId": "1c878ef4-7bde-40b8-9251-37180ecb6ba2"
      },
      "source": [
        "print(\"Training Set Shape :\", train.shape)\n",
        "#print(\"Validation Set Shape :\", val.shape)\n",
        "# print(\"Test Set Shape :\", test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Set Shape : (17142, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CRmICBn0y7Sj",
        "outputId": "64f76561-2244-43b2-e574-08352c380898"
      },
      "source": [
        "DATA_COLUMN = 'text'\n",
        "LABEL_COLUMN = 'label'\n",
        "# The list containing all the classes (train['SECTION'].unique())\n",
        "label_list = [x for x in np.unique(train.label)]\n",
        "label_list"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CePX9HTsQvZj"
      },
      "source": [
        "# Splitting the Data into smaller chunks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNg5-wtmy7Vw"
      },
      "source": [
        "#Splitting the data into smaller chunks \n",
        "def get_split(text1):\n",
        "  l_total = []\n",
        "  l_parcial = []\n",
        "  if len(text1.split())//150 >0:\n",
        "    n = len(text1.split())//150\n",
        "  else: \n",
        "    n = 1\n",
        "  for w in range(n):\n",
        "    if w == 0:\n",
        "      l_parcial = text1.split()[:200]\n",
        "      l_total.append(\" \".join(l_parcial))\n",
        "    else:\n",
        "      l_parcial = text1.split()[w*150:w*150 + 200] #overlapping 50 words in every chunks \n",
        "      l_total.append(\" \".join(l_parcial))\n",
        "  return l_total"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "94x90BiKomPv"
      },
      "source": [
        "def get_split_count(text1):\n",
        "  if len(text1.split())//150 >0:\n",
        "    n = len(text1.split())//150\n",
        "  else: \n",
        "    n = 1\n",
        "  return n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "MZT0Tkphqlc3",
        "outputId": "a9bde686-ce9a-4449-f873-97309b19f7ed"
      },
      "source": [
        "train['text_split'] = train[DATA_COLUMN].apply(get_split)\n",
        "train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>text_split</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>My wife and I went to Huntington Bank applied ...</td>\n",
              "      <td>6</td>\n",
              "      <td>[My wife and I went to Huntington Bank applied...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I disputed fraudulent charges on my credit car...</td>\n",
              "      <td>2</td>\n",
              "      <td>[I disputed fraudulent charges on my credit ca...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>To Whom It May Concern Here is a summary of ev...</td>\n",
              "      <td>6</td>\n",
              "      <td>[To Whom It May Concern Here is a summary of e...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Upon reviewing my Bank of America checking acc...</td>\n",
              "      <td>0</td>\n",
              "      <td>[Upon reviewing my Bank of America checking ac...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>On Tuesday XXXX XXXX I spoke with a representa...</td>\n",
              "      <td>6</td>\n",
              "      <td>[On Tuesday XXXX XXXX I spoke with a represent...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  ...                                         text_split\n",
              "0  My wife and I went to Huntington Bank applied ...  ...  [My wife and I went to Huntington Bank applied...\n",
              "1  I disputed fraudulent charges on my credit car...  ...  [I disputed fraudulent charges on my credit ca...\n",
              "2  To Whom It May Concern Here is a summary of ev...  ...  [To Whom It May Concern Here is a summary of e...\n",
              "3  Upon reviewing my Bank of America checking acc...  ...  [Upon reviewing my Bank of America checking ac...\n",
              "4  On Tuesday XXXX XXXX I spoke with a representa...  ...  [On Tuesday XXXX XXXX I spoke with a represent...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "I1AXyk6R18-5",
        "outputId": "c6cae025-1110-4e9f-ed35-da82deb92de2"
      },
      "source": [
        "train['text_split_count'] = train[DATA_COLUMN].apply(get_split_count)\n",
        "train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>text_split</th>\n",
              "      <th>text_split_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>My wife and I went to Huntington Bank applied ...</td>\n",
              "      <td>6</td>\n",
              "      <td>[My wife and I went to Huntington Bank applied...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I disputed fraudulent charges on my credit car...</td>\n",
              "      <td>2</td>\n",
              "      <td>[I disputed fraudulent charges on my credit ca...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>To Whom It May Concern Here is a summary of ev...</td>\n",
              "      <td>6</td>\n",
              "      <td>[To Whom It May Concern Here is a summary of e...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Upon reviewing my Bank of America checking acc...</td>\n",
              "      <td>0</td>\n",
              "      <td>[Upon reviewing my Bank of America checking ac...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>On Tuesday XXXX XXXX I spoke with a representa...</td>\n",
              "      <td>6</td>\n",
              "      <td>[On Tuesday XXXX XXXX I spoke with a represent...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  ...  text_split_count\n",
              "0  My wife and I went to Huntington Bank applied ...  ...                 4\n",
              "1  I disputed fraudulent charges on my credit car...  ...                 2\n",
              "2  To Whom It May Concern Here is a summary of ev...  ...                 3\n",
              "3  Upon reviewing my Bank of America checking acc...  ...                 1\n",
              "4  On Tuesday XXXX XXXX I spoke with a representa...  ...                 3\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-rhAKpQ5W0Hi",
        "outputId": "a2612fa2-0f7d-43e4-c2b0-9cd8debea207"
      },
      "source": [
        "train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(17142, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_dYA9QVp_Bw"
      },
      "source": [
        "count_1 =0\n",
        "count_2 =0\n",
        "count_3 =0\n",
        "count_4 =0\n",
        "count_5 =0\n",
        "for i in train['text_split_count']:\n",
        "  if i==5:\n",
        "    count_5+=1\n",
        "  if i==1:\n",
        "    count_1+=1\n",
        "  if i==2:\n",
        "    count_2+=1\n",
        "  if i==3:\n",
        "    count_3+=1\n",
        "  if i==4:\n",
        "    count_4+=1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wYS52j7xrWYL",
        "outputId": "3e780a55-54a9-4914-f694-fd04816273a8"
      },
      "source": [
        "print('count_1 ', count_1)\n",
        "print('count_2 ', count_2)\n",
        "print('count_3 ', count_3)\n",
        "print('count_4 ', count_4)\n",
        "print('count_5 ', count_5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "count_1  4045\n",
            "count_2  6873\n",
            "count_3  3264\n",
            "count_4  2758\n",
            "count_5  202\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5HgHYvLpVjN0"
      },
      "source": [
        "#creating the test set\n",
        "test_set = train[(train['text_split_count'] == 5)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "zw29kiyKXHu_",
        "outputId": "64794a4c-ab51-4826-df74-d7ac90826745"
      },
      "source": [
        "test_set"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>text_split</th>\n",
              "      <th>text_split_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>94</th>\n",
              "      <td>I took out a loan in XXXX XXXX that is being s...</td>\n",
              "      <td>9</td>\n",
              "      <td>[I took out a loan in XXXX XXXX that is being ...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>132</th>\n",
              "      <td>Well the first step I went to XXXX in XXXX XXX...</td>\n",
              "      <td>1</td>\n",
              "      <td>[Well the first step I went to XXXX in XXXX XX...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>307</th>\n",
              "      <td>I called Making homes affordable last night ag...</td>\n",
              "      <td>6</td>\n",
              "      <td>[I called Making homes affordable last night a...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>325</th>\n",
              "      <td>I d like to complain about the way Bank of Ame...</td>\n",
              "      <td>6</td>\n",
              "      <td>[I d like to complain about the way Bank of Am...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>372</th>\n",
              "      <td>I first contacted PNC to get a mortgage and my...</td>\n",
              "      <td>6</td>\n",
              "      <td>[I first contacted PNC to get a mortgage and m...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16554</th>\n",
              "      <td>This complaint is regarding SYNCHRONY FINANCIA...</td>\n",
              "      <td>2</td>\n",
              "      <td>[This complaint is regarding SYNCHRONY FINANCI...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16846</th>\n",
              "      <td>I lost my home of 25 years to a preditory lend...</td>\n",
              "      <td>6</td>\n",
              "      <td>[I lost my home of 25 years to a preditory len...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16868</th>\n",
              "      <td>I encountered a hardship situation XX XX XXXX ...</td>\n",
              "      <td>6</td>\n",
              "      <td>[I encountered a hardship situation XX XX XXXX...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16893</th>\n",
              "      <td>I went into a local XXXX office to let them he...</td>\n",
              "      <td>2</td>\n",
              "      <td>[I went into a local XXXX office to let them h...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17116</th>\n",
              "      <td>We are XXXX and XXXX XXXX and we lived at XXXX...</td>\n",
              "      <td>6</td>\n",
              "      <td>[We are XXXX and XXXX XXXX and we lived at XXX...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>202 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    text  ...  text_split_count\n",
              "94     I took out a loan in XXXX XXXX that is being s...  ...                 5\n",
              "132    Well the first step I went to XXXX in XXXX XXX...  ...                 5\n",
              "307    I called Making homes affordable last night ag...  ...                 5\n",
              "325    I d like to complain about the way Bank of Ame...  ...                 5\n",
              "372    I first contacted PNC to get a mortgage and my...  ...                 5\n",
              "...                                                  ...  ...               ...\n",
              "16554  This complaint is regarding SYNCHRONY FINANCIA...  ...                 5\n",
              "16846  I lost my home of 25 years to a preditory lend...  ...                 5\n",
              "16868  I encountered a hardship situation XX XX XXXX ...  ...                 5\n",
              "16893  I went into a local XXXX office to let them he...  ...                 5\n",
              "17116  We are XXXX and XXXX XXXX and we lived at XXXX...  ...                 5\n",
              "\n",
              "[202 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CVSCIgHSe5dJ",
        "outputId": "d51bd3f3-e0f2-43e5-8b30-2c9ce2fa2d8d"
      },
      "source": [
        "train.shape , test_set.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((17142, 4), (202, 4))"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MybNDg86fSEt"
      },
      "source": [
        "train = train[(train['text_split_count'].isin([1,2,3,4]))]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bT7AbZN3fmrQ",
        "outputId": "b4dbebac-3e9c-4670-e412-7b9adbba0452"
      },
      "source": [
        "train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(16940, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "XYkYPXkquWPq",
        "outputId": "2c779e3f-8cfb-4738-8d6f-64f79b6291b2"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train, val = train_test_split(train, test_size=0.2, random_state=35)\n",
        "train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>text_split</th>\n",
              "      <th>text_split_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>12325</th>\n",
              "      <td>I requested detailed accounting of payments ch...</td>\n",
              "      <td>3</td>\n",
              "      <td>[I requested detailed accounting of payments c...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12032</th>\n",
              "      <td>Citibank offered to me as consideration a bonu...</td>\n",
              "      <td>2</td>\n",
              "      <td>[Citibank offered to me as consideration a bon...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1160</th>\n",
              "      <td>I have been using Chase Freedom credit card si...</td>\n",
              "      <td>2</td>\n",
              "      <td>[I have been using Chase Freedom credit card s...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1283</th>\n",
              "      <td>XX XX XXXX after numerous challenges including...</td>\n",
              "      <td>3</td>\n",
              "      <td>[XX XX XXXX after numerous challenges includin...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10129</th>\n",
              "      <td>Today I am requesting assistance with several ...</td>\n",
              "      <td>6</td>\n",
              "      <td>[Today I am requesting assistance with several...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    text  ...  text_split_count\n",
              "12325  I requested detailed accounting of payments ch...  ...                 2\n",
              "12032  Citibank offered to me as consideration a bonu...  ...                 3\n",
              "1160   I have been using Chase Freedom credit card si...  ...                 1\n",
              "1283   XX XX XXXX after numerous challenges including...  ...                 1\n",
              "10129  Today I am requesting assistance with several ...  ...                 3\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-HB6fcp-hj3z",
        "outputId": "b2e34544-8a1d-4c63-a325-872305ddf57b"
      },
      "source": [
        "train.shape, val.shape, test_set.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((13552, 4), (3388, 4), (202, 4))"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Emmt1I-U19EH",
        "outputId": "86b8fc1c-19ad-4859-b2a8-a814c748aa98"
      },
      "source": [
        "train_l = []\n",
        "label_l = []\n",
        "index_l =[]\n",
        "for idx,row in train.iterrows():\n",
        "  for l in row['text_split']:  #it is going to create list of training chunks with label and index mapping \n",
        "    train_l.append(l)\n",
        "    label_l.append(row['label'])\n",
        "    index_l.append(idx)\n",
        "len(train_l), len(label_l), len(index_l)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(30880, 30880, 30880)"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0aZq4QA7a79t",
        "outputId": "c9ce449a-fc5a-4264-b2ab-dd32b78fa462"
      },
      "source": [
        "val_l = []\n",
        "val_label_l = []\n",
        "val_index_l = []\n",
        "for idx,row in val.iterrows():\n",
        "  for l in row['text_split']:\n",
        "    val_l.append(l)\n",
        "    val_label_l.append(row['label'])\n",
        "    val_index_l.append(idx)\n",
        "len(val_l), len(val_label_l), len(val_index_l)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7735, 7735, 7735)"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uENg5e4E19G7",
        "outputId": "621f3d76-5f55-4040-bb22-3a834b1bda2f"
      },
      "source": [
        "test_l = []\n",
        "test_label_l = []\n",
        "test_index_l = []\n",
        "for idx,row in test_set.iterrows():\n",
        "  for l in row['text_split']:\n",
        "    test_l.append(l)\n",
        "    test_label_l.append(row['label'])\n",
        "    test_index_l.append(idx)\n",
        "len(test_l), len(test_label_l), len(test_index_l)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1010, 1010, 1010)"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "51RfS2C519JW",
        "outputId": "6ae1bb67-1ee6-4575-ada6-2ec100d51a59"
      },
      "source": [
        "train_df = pd.DataFrame({DATA_COLUMN:train_l, LABEL_COLUMN:label_l})\n",
        "train_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I requested detailed accounting of payments ch...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>not They chose only to update the account even...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Citibank offered to me as consideration a bonu...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>s offer Specifically when I attempted to purch...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>in person and purchase a phone in store This r...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  label\n",
              "0  I requested detailed accounting of payments ch...      3\n",
              "1  not They chose only to update the account even...      3\n",
              "2  Citibank offered to me as consideration a bonu...      2\n",
              "3  s offer Specifically when I attempted to purch...      2\n",
              "4  in person and purchase a phone in store This r...      2"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "_CfhlZ-HbmO3",
        "outputId": "9f3b6c72-658f-4783-848a-f8efba27f23f"
      },
      "source": [
        "val_df = pd.DataFrame({DATA_COLUMN:val_l, LABEL_COLUMN:val_label_l})\n",
        "val_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I decided to invest my money with Raymond Jame...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>of times I would not suffer more than a 10 los...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I received an email yesterday XXXX XXXX 15 sta...</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>I received a phone call from a representative ...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>states otherwise It clearly states I have 30 d...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  label\n",
              "0  I decided to invest my money with Raymond Jame...      0\n",
              "1  of times I would not suffer more than a 10 los...      0\n",
              "2  I received an email yesterday XXXX XXXX 15 sta...      8\n",
              "3  I received a phone call from a representative ...      4\n",
              "4  states otherwise It clearly states I have 30 d...      4"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "X6rGj8Esbnr-",
        "outputId": "dfd40123-40c7-4af0-ebc1-ae2e4583dde1"
      },
      "source": [
        "test_df = pd.DataFrame({DATA_COLUMN:test_l, LABEL_COLUMN:test_label_l})\n",
        "test_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I took out a loan in XXXX XXXX that is being s...</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>know it would nt be sent because my loan could...</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>used XXXX months in XX XX XXXX the rep told me...</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ACS rep told me they legally could not stop th...</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I informed her this was again ACS modifying pe...</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  label\n",
              "0  I took out a loan in XXXX XXXX that is being s...      9\n",
              "1  know it would nt be sent because my loan could...      9\n",
              "2  used XXXX months in XX XX XXXX the rep told me...      9\n",
              "3  ACS rep told me they legally could not stop th...      9\n",
              "4  I informed her this was again ACS modifying pe...      9"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5UkFxeVbXHPi",
        "outputId": "4a111c77-6c52-4de9-892c-c299634bd9cf"
      },
      "source": [
        "print('train_df shape : ',train_df.shape)\n",
        "print('val_df shape : ',val_df.shape)\n",
        "print('test_df shape : ',test_df.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_df shape :  (30880, 2)\n",
            "val_df shape :  (7735, 2)\n",
            "test_df shape :  (1010, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gGlfUu51SQ1c"
      },
      "source": [
        "# BERT: Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFqwAgdEDMR8"
      },
      "source": [
        "class PaddingInputExample(object):\n",
        "      pass\n",
        "\n",
        "class InputExample(object):\n",
        "    \"\"\"A single training/test example for simple sequence classification.\"\"\"\n",
        "\n",
        "    def __init__(self, guid, text_a, text_b=None, label=None):\n",
        "        \n",
        "        \"\"\"Constructs a InputExample.\n",
        "    Args:\n",
        "      guid: Unique id for the example.\n",
        "      text_a: string. The untokenized text of the first sequence. For single\n",
        "        sequence tasks, only this sequence must be specified.\n",
        "      text_b: (Optional) string. The untokenized text of the second sequence.\n",
        "        Only must be specified for sequence pair tasks.\n",
        "      label: (Optional) string. The label of the example. This should be\n",
        "        specified for train and dev examples, but not for test examples.\n",
        "    \"\"\"\n",
        "        self.guid = guid\n",
        "        self.text_a = text_a\n",
        "        self.text_b = text_b\n",
        "        self.label = label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vegh-oReDMUw"
      },
      "source": [
        "train_InputExamples_1 = train_df.apply(lambda x: InputExample(guid=None,\n",
        "                                                                  text_a = x[DATA_COLUMN], \n",
        "                                                                  text_b = None, \n",
        "                                                                  label = x[LABEL_COLUMN]), axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Lwdle-FDMXj",
        "outputId": "b7f40fde-8725-47a7-d2fe-f323b3696ae9"
      },
      "source": [
        "train_InputExamples_1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        <__main__.InputExample object at 0x7fbadfbc81d0>\n",
              "1        <__main__.InputExample object at 0x7fbadfbc8110>\n",
              "2        <__main__.InputExample object at 0x7fbadfbbad50>\n",
              "3        <__main__.InputExample object at 0x7fbadfbbaf50>\n",
              "4        <__main__.InputExample object at 0x7fbadf8d0990>\n",
              "                               ...                       \n",
              "30875    <__main__.InputExample object at 0x7fbadf20b190>\n",
              "30876    <__main__.InputExample object at 0x7fbadf20b1d0>\n",
              "30877    <__main__.InputExample object at 0x7fbadf20b210>\n",
              "30878    <__main__.InputExample object at 0x7fbadf20b250>\n",
              "30879    <__main__.InputExample object at 0x7fbadf20b290>\n",
              "Length: 30880, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "splGqF_aDbjm",
        "outputId": "359c3826-bf8d-4a53-8618-613c9cb14f74"
      },
      "source": [
        "print(\"Row 0 - guid of training set : \", train_InputExamples_1.iloc[0].guid)\n",
        "print(\"\\n__________\\nRow 0 - text_a of training set : \", train_InputExamples_1.iloc[0].text_a)\n",
        "print(\"\\n__________\\nRow 0 - text_b of training set : \", train_InputExamples_1.iloc[0].text_b)\n",
        "print(\"\\n__________\\nRow 0 - label of training set : \", train_InputExamples_1.iloc[0].label)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Row 0 - guid of training set :  None\n",
            "\n",
            "__________\n",
            "Row 0 - text_a of training set :  I requested detailed accounting of payments charges along with an explanation of any charges how those fees were calculated copy of original contract with original creditor documentation on sale of the repossessed car amount applied to account copy of repossession papers in connection with a XXXX XXXX account showing up on my credit report I filed a dispute with TransUnion on XXXX XXXX 2015 they stated they received a letter that states simply that the account was accurate then made changes to XXXX dates there no was verification to prove the account is accurate valid included with the statement They did nt even receive verification showing the account is even my account no original signed contract with original creditor According to FCRA section 611 c if they did not receive the detailed verification that was requested showing the account is valid accurate they are required to remove it They did not They chose only to update the account even though they had not received any verification showing its validity or accuracy They refused to provide me with a copy of the letter they received from XXXX XXXX I received no written results of investigation which I should have received within\n",
            "\n",
            "__________\n",
            "Row 0 - text_b of training set :  None\n",
            "\n",
            "__________\n",
            "Row 0 - label of training set :  3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5QGCTIhmDpoZ"
      },
      "source": [
        "val_InputExamples_1 = val_df.apply(lambda x: InputExample(guid=None, \n",
        "                                                                   text_a = x[DATA_COLUMN], \n",
        "                                                                   text_b = None, \n",
        "                                                                   label = x[LABEL_COLUMN]), axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6PgnWouab3ZG"
      },
      "source": [
        "test_InputExamples_1 = test_df.apply(lambda x: InputExample(guid=None, \n",
        "                                                                   text_a = x[DATA_COLUMN], \n",
        "                                                                   text_b = None, \n",
        "                                                                   label = x[LABEL_COLUMN]), axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lUbc22wTTvkQ"
      },
      "source": [
        "# BERT: Loading the pre-trained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BO7PECyJRh37"
      },
      "source": [
        "import official.nlp.bert.tokenization as tokenization"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EWFFUaGwDyVv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c398cab-f134-4a5d-a641-6a93699286d1"
      },
      "source": [
        "# ##We are creatung the tokens to gorm the vocabulary which inturn is ued to represent the words\n",
        "# #BERT: Loading the pre-trained model\n",
        "# This is a path to an uncased (all lowercase) version of BERT\n",
        "BERT_MODEL_HUB = \"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\"\n",
        "\n",
        "def create_tokenizer_from_hub_module():\n",
        "  \"\"\"Get the vocab file and casing info from the Hub module.\"\"\"\n",
        "  with tf.Graph().as_default():\n",
        "    bert_module = hub.Module(BERT_MODEL_HUB)\n",
        "    tokenization_info = bert_module(signature=\"tokenization_info\", as_dict=True)\n",
        "    with tf.compat.v1.Session() as sess:\n",
        "      vocab_file, do_lower_case = sess.run([tokenization_info[\"vocab_file\"],\n",
        "                                            tokenization_info[\"do_lower_case\"]])\n",
        "      \n",
        "  return tokenization.FullTokenizer(\n",
        "      vocab_file=vocab_file, do_lower_case=do_lower_case)\n",
        "\n",
        "tokenizer = create_tokenizer_from_hub_module()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dttRQBafVA1q",
        "outputId": "c64fe389-81bd-4233-ded9-8c9aeb855fba"
      },
      "source": [
        "len(tokenizer.vocab.keys())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30522"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Do9OnHpRGJqp"
      },
      "source": [
        "#Defining Input features \n",
        "class InputFeatures(object):\n",
        "  \"\"\"A single set of features of data.\"\"\"\n",
        "\n",
        "  def __init__(self,\n",
        "               input_ids,\n",
        "               input_mask,\n",
        "               segment_ids,\n",
        "               label_id,\n",
        "               is_real_example=True):\n",
        "    self.input_ids = input_ids\n",
        "    self.input_mask = input_mask\n",
        "    self.segment_ids = segment_ids\n",
        "    self.label_id = label_id\n",
        "    self.is_real_example = is_real_example"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LMCVuhwOVwE3"
      },
      "source": [
        "def convert_single_example(tokenizer, example, max_seq_length=256):\n",
        "    \"\"\"Converts a single `InputExample` into a single `InputFeatures`.\"\"\"\n",
        "\n",
        "    if isinstance(example, PaddingInputExample):\n",
        "        input_ids = [0] * max_seq_length\n",
        "        input_mask = [0] * max_seq_length\n",
        "        segment_ids = [0] * max_seq_length\n",
        "        label = 0\n",
        "        return input_ids, input_mask, segment_ids, label\n",
        "\n",
        "    tokens_a = tokenizer.tokenize(example.text_a)\n",
        "    if len(tokens_a) > max_seq_length - 2:\n",
        "        tokens_a = tokens_a[0 : (max_seq_length - 2)]\n",
        "\n",
        "    tokens = []\n",
        "    segment_ids = []\n",
        "    tokens.append(\"[CLS]\")\n",
        "    segment_ids.append(0)\n",
        "    for token in tokens_a:\n",
        "        tokens.append(token)\n",
        "        segment_ids.append(0)\n",
        "    tokens.append(\"[SEP]\")\n",
        "    segment_ids.append(0)\n",
        "\n",
        "    input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "\n",
        "    # The mask has 1 for real tokens and 0 for padding tokens. Only real\n",
        "    # tokens are attended to.\n",
        "    input_mask = [1] * len(input_ids)\n",
        "\n",
        "    # Zero-pad up to the sequence length.\n",
        "    while len(input_ids) < max_seq_length:\n",
        "        input_ids.append(0)\n",
        "        input_mask.append(0)\n",
        "        segment_ids.append(0)\n",
        "\n",
        "    assert len(input_ids) == max_seq_length\n",
        "    assert len(input_mask) == max_seq_length\n",
        "    assert len(segment_ids) == max_seq_length\n",
        "\n",
        "    return input_ids, input_mask, segment_ids, example.label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBbW4pfSKjfR"
      },
      "source": [
        "def convert_examples_to_features(tokenizer, examples, max_seq_length=200):\n",
        "    \"\"\"Convert a set of `InputExample`s to a list of `InputFeatures`.\"\"\"\n",
        "\n",
        "    input_ids, input_masks, segment_ids, labels,features = [], [], [], [],[]\n",
        "    for example in tqdm.tqdm(examples, desc=\"Converting examples to features\"):\n",
        "        input_id, input_mask, segment_id, label = convert_single_example(\n",
        "            tokenizer, example, max_seq_length\n",
        "        )\n",
        "\n",
        "        input_ids.append(input_id)\n",
        "        input_masks.append(input_mask)\n",
        "        segment_ids.append(segment_id)\n",
        "        labels.append(label)\n",
        "\n",
        "        feature = InputFeatures(input_ids=input_id,\n",
        "        input_mask=input_mask,\n",
        "        segment_ids=segment_id,\n",
        "        label_id=label,\n",
        "        is_real_example=True)\n",
        "\n",
        "        features.append(feature)\n",
        "    # return(\n",
        "    #     np.array(input_ids),\n",
        "    #     np.array(input_masks),\n",
        "    #     np.array(segment_ids),\n",
        "    #     np.array(labels).reshape(-1, 1),\n",
        "    # )\n",
        "    return features"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9vdlwHPV9Nk"
      },
      "source": [
        "import tqdm\n",
        "MAX_SEQ_LENGTH = 200"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WSjQpmcAGJ0t",
        "outputId": "cdf62d27-1e34-44d1-d287-0eb7bd1177c6"
      },
      "source": [
        "# Convert our train and validation features to InputFeatures that BERT understands.\n",
        "\n",
        "train_features = convert_examples_to_features(tokenizer, train_InputExamples_1, MAX_SEQ_LENGTH)\n",
        "\n",
        "val_features = convert_examples_to_features(tokenizer, val_InputExamples_1, MAX_SEQ_LENGTH)\n",
        "\n",
        "test_features = convert_examples_to_features(tokenizer, test_InputExamples_1, MAX_SEQ_LENGTH)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Converting examples to features: 100%|██████████| 30880/30880 [01:39<00:00, 311.43it/s]\n",
            "Converting examples to features: 100%|██████████| 7735/7735 [00:24<00:00, 314.24it/s]\n",
            "Converting examples to features: 100%|██████████| 1010/1010 [00:02<00:00, 336.68it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aDzWg7l1oXi9",
        "outputId": "6cc3c311-1736-4ab5-d1fa-20659ca47e1e"
      },
      "source": [
        "print(\"Sentence : \", train_InputExamples_1.iloc[0].text_a)\n",
        "print(\"-\"*30)\n",
        "print(\"Tokens : \", tokenizer.tokenize(train_InputExamples_1.iloc[0].text_a))\n",
        "print(\"-\"*30)\n",
        "print(\"Input IDs : \", train_features[0].input_ids)\n",
        "print(\"-\"*30)\n",
        "print(\"Input Masks : \", train_features[0].input_mask)\n",
        "print(\"-\"*30)\n",
        "print(\"Segment IDs : \", train_features[0].segment_ids)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence :  I requested detailed accounting of payments charges along with an explanation of any charges how those fees were calculated copy of original contract with original creditor documentation on sale of the repossessed car amount applied to account copy of repossession papers in connection with a XXXX XXXX account showing up on my credit report I filed a dispute with TransUnion on XXXX XXXX 2015 they stated they received a letter that states simply that the account was accurate then made changes to XXXX dates there no was verification to prove the account is accurate valid included with the statement They did nt even receive verification showing the account is even my account no original signed contract with original creditor According to FCRA section 611 c if they did not receive the detailed verification that was requested showing the account is valid accurate they are required to remove it They did not They chose only to update the account even though they had not received any verification showing its validity or accuracy They refused to provide me with a copy of the letter they received from XXXX XXXX I received no written results of investigation which I should have received within\n",
            "------------------------------\n",
            "Tokens :  ['i', 'requested', 'detailed', 'accounting', 'of', 'payments', 'charges', 'along', 'with', 'an', 'explanation', 'of', 'any', 'charges', 'how', 'those', 'fees', 'were', 'calculated', 'copy', 'of', 'original', 'contract', 'with', 'original', 'credit', '##or', 'documentation', 'on', 'sale', 'of', 'the', 'rep', '##oss', '##essed', 'car', 'amount', 'applied', 'to', 'account', 'copy', 'of', 'rep', '##oss', '##ess', '##ion', 'papers', 'in', 'connection', 'with', 'a', 'xx', '##xx', 'xx', '##xx', 'account', 'showing', 'up', 'on', 'my', 'credit', 'report', 'i', 'filed', 'a', 'dispute', 'with', 'trans', '##uni', '##on', 'on', 'xx', '##xx', 'xx', '##xx', '2015', 'they', 'stated', 'they', 'received', 'a', 'letter', 'that', 'states', 'simply', 'that', 'the', 'account', 'was', 'accurate', 'then', 'made', 'changes', 'to', 'xx', '##xx', 'dates', 'there', 'no', 'was', 'verification', 'to', 'prove', 'the', 'account', 'is', 'accurate', 'valid', 'included', 'with', 'the', 'statement', 'they', 'did', 'nt', 'even', 'receive', 'verification', 'showing', 'the', 'account', 'is', 'even', 'my', 'account', 'no', 'original', 'signed', 'contract', 'with', 'original', 'credit', '##or', 'according', 'to', 'fc', '##ra', 'section', '61', '##1', 'c', 'if', 'they', 'did', 'not', 'receive', 'the', 'detailed', 'verification', 'that', 'was', 'requested', 'showing', 'the', 'account', 'is', 'valid', 'accurate', 'they', 'are', 'required', 'to', 'remove', 'it', 'they', 'did', 'not', 'they', 'chose', 'only', 'to', 'update', 'the', 'account', 'even', 'though', 'they', 'had', 'not', 'received', 'any', 'verification', 'showing', 'its', 'validity', 'or', 'accuracy', 'they', 'refused', 'to', 'provide', 'me', 'with', 'a', 'copy', 'of', 'the', 'letter', 'they', 'received', 'from', 'xx', '##xx', 'xx', '##xx', 'i', 'received', 'no', 'written', 'results', 'of', 'investigation', 'which', 'i', 'should', 'have', 'received', 'within']\n",
            "------------------------------\n",
            "Input IDs :  [101, 1045, 7303, 6851, 9529, 1997, 10504, 5571, 2247, 2007, 2019, 7526, 1997, 2151, 5571, 2129, 2216, 9883, 2020, 10174, 6100, 1997, 2434, 3206, 2007, 2434, 4923, 2953, 12653, 2006, 5096, 1997, 1996, 16360, 15094, 23656, 2482, 3815, 4162, 2000, 4070, 6100, 1997, 16360, 15094, 7971, 3258, 4981, 1999, 4434, 2007, 1037, 22038, 20348, 22038, 20348, 4070, 4760, 2039, 2006, 2026, 4923, 3189, 1045, 6406, 1037, 7593, 2007, 9099, 19496, 2239, 2006, 22038, 20348, 22038, 20348, 2325, 2027, 3090, 2027, 2363, 1037, 3661, 2008, 2163, 3432, 2008, 1996, 4070, 2001, 8321, 2059, 2081, 3431, 2000, 22038, 20348, 5246, 2045, 2053, 2001, 22616, 2000, 6011, 1996, 4070, 2003, 8321, 9398, 2443, 2007, 1996, 4861, 2027, 2106, 23961, 2130, 4374, 22616, 4760, 1996, 4070, 2003, 2130, 2026, 4070, 2053, 2434, 2772, 3206, 2007, 2434, 4923, 2953, 2429, 2000, 4429, 2527, 2930, 6079, 2487, 1039, 2065, 2027, 2106, 2025, 4374, 1996, 6851, 22616, 2008, 2001, 7303, 4760, 1996, 4070, 2003, 9398, 8321, 2027, 2024, 3223, 2000, 6366, 2009, 2027, 2106, 2025, 2027, 4900, 2069, 2000, 10651, 1996, 4070, 2130, 2295, 2027, 2018, 2025, 2363, 2151, 22616, 4760, 2049, 16406, 2030, 10640, 2027, 4188, 2000, 3073, 2033, 2007, 1037, 6100, 1997, 1996, 3661, 102]\n",
            "------------------------------\n",
            "Input Masks :  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "------------------------------\n",
            "Segment IDs :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJ943C4bWMK2"
      },
      "source": [
        "def create_model(is_predicting, input_ids, input_mask, segment_ids, labels,\n",
        "                 num_labels):\n",
        "  \n",
        "  bert_module = hub.Module(\n",
        "      BERT_MODEL_HUB,\n",
        "      trainable=True)\n",
        "  bert_inputs = dict(\n",
        "      input_ids=input_ids,\n",
        "      input_mask=input_mask,\n",
        "      segment_ids=segment_ids)\n",
        "  bert_outputs = bert_module(\n",
        "      inputs=bert_inputs,\n",
        "      signature=\"tokens\",\n",
        "      as_dict=True)\n",
        "\n",
        "  # Use \"pooled_output\" for classification tasks on an entire sentence.\n",
        "  # Use \"sequence_outputs\" for token-level output.\n",
        "  output_layer = bert_outputs[\"pooled_output\"]\n",
        "  # with tf.Session() as sess:\n",
        "  output_layer1 = bert_outputs[\"pooled_output\"]\n",
        "  # output_layer1 = 999\n",
        "  hidden_size = output_layer.shape[-1]\n",
        "\n",
        "  # Create our own layer to tune for politeness data.\n",
        "  output_weights = tf.get_variable(\n",
        "      \"output_weights\", [num_labels, hidden_size],\n",
        "      initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
        "\n",
        "  output_bias = tf.get_variable(\n",
        "      \"output_bias\", [num_labels], initializer=tf.zeros_initializer())\n",
        "\n",
        "  with tf.variable_scope(\"loss\"):\n",
        "\n",
        "    # Dropout helps prevent overfitting\n",
        "    output_layer = tf.nn.dropout(output_layer, keep_prob=0.8)\n",
        "\n",
        "    logits = tf.matmul(output_layer, output_weights, transpose_b=True)\n",
        "    logits = tf.nn.bias_add(logits, output_bias)\n",
        "    log_probs = tf.nn.log_softmax(logits, axis=-1)\n",
        "\n",
        "    # Convert labels into one-hot encoding\n",
        "    one_hot_labels = tf.one_hot(labels, depth=num_labels, dtype=tf.float32)\n",
        "\n",
        "    predicted_labels = tf.squeeze(tf.argmax(log_probs, axis=-1, output_type=tf.int32))\n",
        "    # If we're predicting, we want predicted labels and the probabiltiies.\n",
        "    if is_predicting:\n",
        "      return (predicted_labels, log_probs, output_layer1)\n",
        "\n",
        "    # If we're train/eval, compute loss between predicted and actual label\n",
        "    per_example_loss = -tf.reduce_sum(one_hot_labels * log_probs, axis=-1)\n",
        "    loss = tf.reduce_mean(per_example_loss)\n",
        "    return (loss, predicted_labels, log_probs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97j2dxcMWQXu"
      },
      "source": [
        "def model_fn_builder(num_labels, learning_rate, num_train_steps,\n",
        "                     num_warmup_steps):\n",
        "  \"\"\"Returns `model_fn` closure for TPUEstimator.\"\"\"\n",
        "  def model_fn(features, labels, mode, params):  # pylint: disable=unused-argument\n",
        "    \"\"\"The `model_fn` for TPUEstimator.\"\"\"\n",
        "\n",
        "    input_ids = features[\"input_ids\"]\n",
        "    input_mask = features[\"input_mask\"]\n",
        "    segment_ids = features[\"segment_ids\"]\n",
        "    label_ids = features[\"label_ids\"]\n",
        "\n",
        "    is_predicting = (mode == tf.estimator.ModeKeys.PREDICT)\n",
        "    \n",
        "    # TRAIN and EVAL\n",
        "    if not is_predicting:\n",
        "\n",
        "      (loss, predicted_labels, log_probs) = create_model(\n",
        "        is_predicting, input_ids, input_mask, segment_ids, label_ids, num_labels)\n",
        "\n",
        "      train_op = bert.optimization.create_optimizer(\n",
        "          loss, learning_rate, num_train_steps, num_warmup_steps, use_tpu=False)\n",
        "\n",
        "      # Calculate evaluation metrics. \n",
        "      def metric_fn(label_ids, predicted_labels):\n",
        "        accuracy = tf.metrics.accuracy(label_ids, predicted_labels)\n",
        "        true_pos = tf.metrics.true_positives(\n",
        "            label_ids,\n",
        "            predicted_labels)\n",
        "        true_neg = tf.metrics.true_negatives(\n",
        "            label_ids,\n",
        "            predicted_labels)   \n",
        "        false_pos = tf.metrics.false_positives(\n",
        "            label_ids,\n",
        "            predicted_labels)  \n",
        "        false_neg = tf.metrics.false_negatives(\n",
        "            label_ids,\n",
        "            predicted_labels)\n",
        "        \n",
        "        return {\n",
        "            \"eval_accuracy\": accuracy,\n",
        "            \"true_positives\": true_pos,\n",
        "            \"true_negatives\": true_neg,\n",
        "            \"false_positives\": false_pos,\n",
        "            \"false_negatives\": false_neg,\n",
        "            }\n",
        "\n",
        "      eval_metrics = metric_fn(label_ids, predicted_labels)\n",
        "\n",
        "      if mode == tf.estimator.ModeKeys.TRAIN:\n",
        "        return tf.estimator.EstimatorSpec(mode=mode,\n",
        "          loss=loss,\n",
        "          train_op=train_op)\n",
        "      else:\n",
        "          return tf.estimator.EstimatorSpec(mode=mode,\n",
        "            loss=loss,\n",
        "            eval_metric_ops=eval_metrics)\n",
        "    else:\n",
        "      (predicted_labels, log_probs, output_layer) = create_model(\n",
        "        is_predicting, input_ids, input_mask, segment_ids, label_ids, num_labels)\n",
        "      predictions = {\n",
        "          'probabilities': log_probs,\n",
        "          'labels': predicted_labels,\n",
        "          'pooled_output': output_layer\n",
        "      }\n",
        "      return tf.estimator.EstimatorSpec(mode, predictions=predictions)\n",
        "\n",
        "  # Return the actual model function in the closure\n",
        "  return model_fn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "krNx-z91Izx4"
      },
      "source": [
        "BATCH_SIZE = 16\n",
        "LEARNING_RATE = 2e-5\n",
        "NUM_TRAIN_EPOCHS = 1.0\n",
        "# Warmup is a period of time where the learning rate is small and gradually increases--usually helps training.\n",
        "WARMUP_PROPORTION = 0.1\n",
        "# Model configs\n",
        "SAVE_CHECKPOINTS_STEPS = 300\n",
        "SAVE_SUMMARY_STEPS = 100\n",
        "\n",
        "# # Compute train and warmup steps from batch size\n",
        "num_train_steps = int(len(train_features) / BATCH_SIZE * NUM_TRAIN_EPOCHS)\n",
        "num_warmup_steps = int(num_train_steps * WARMUP_PROPORTION)\n",
        "\n",
        "# Specify output directory and number of checkpoint steps to save\n",
        "run_config = tf.estimator.RunConfig(\n",
        "    model_dir=OUTPUT_DIR,\n",
        "    save_summary_steps=SAVE_SUMMARY_STEPS,\n",
        "    save_checkpoints_steps=SAVE_CHECKPOINTS_STEPS)\n",
        "\n",
        "# Specify output directory and number of checkpoint steps to save\n",
        "run_config = tf.estimator.RunConfig(\n",
        "    model_dir=OUTPUT_DIR,\n",
        "    save_summary_steps=SAVE_SUMMARY_STEPS,\n",
        "    save_checkpoints_steps=SAVE_CHECKPOINTS_STEPS)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TVqAeS5MI39i",
        "outputId": "12cfc18b-b920-49aa-e298-42c404b34492"
      },
      "source": [
        "num_train_steps, len(label_list)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1930, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "umpZ4k9gWdpu"
      },
      "source": [
        "#Initializing the model and the estimator   <USE THIS BLOCK IF YOU ARE TRAINING FOR THE FIRST TIME>\n",
        "# model_fn = model_fn_builder(\n",
        "#   num_labels=len(label_list),\n",
        "#   learning_rate=LEARNING_RATE,\n",
        "#   num_train_steps=num_train_steps,\n",
        "#   num_warmup_steps=num_warmup_steps)\n",
        "\n",
        "# estimator = tf.estimator.Estimator(\n",
        "#   model_fn=model_fn,\n",
        "#   config=run_config,\n",
        "#   params={\"batch_size\": BATCH_SIZE})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oSmYWE9WWwEG"
      },
      "source": [
        "def input_fn_builder(features, seq_length, is_training, drop_remainder):\n",
        "  \"\"\"Creates an `input_fn` closure to be passed to TPUEstimator.\"\"\"\n",
        "\n",
        "  all_input_ids = []\n",
        "  all_input_mask = []\n",
        "  all_segment_ids = []\n",
        "  all_label_ids = []\n",
        "\n",
        "  for feature in features:\n",
        "    all_input_ids.append(feature.input_ids)\n",
        "    all_input_mask.append(feature.input_mask)\n",
        "    all_segment_ids.append(feature.segment_ids)\n",
        "    all_label_ids.append(feature.label_id)\n",
        "\n",
        "  def input_fn(params):\n",
        "    \"\"\"The actual input function.\"\"\"\n",
        "    batch_size = params[\"batch_size\"]\n",
        "\n",
        "    num_examples = len(features)\n",
        "\n",
        "    # This is for demo purposes and does NOT scale to large data sets. We do\n",
        "    # not use Dataset.from_generator() because that uses tf.py_func which is\n",
        "    # not TPU compatible. The right way to load data is with TFRecordReader.\n",
        "    d = tf.data.Dataset.from_tensor_slices({\n",
        "        \"input_ids\":\n",
        "            tf.constant(\n",
        "                all_input_ids, shape=[num_examples, seq_length],\n",
        "                dtype=tf.int32),\n",
        "        \"input_mask\":\n",
        "            tf.constant(\n",
        "                all_input_mask,\n",
        "                shape=[num_examples, seq_length],\n",
        "                dtype=tf.int32),\n",
        "        \"segment_ids\":\n",
        "            tf.constant(\n",
        "                all_segment_ids,\n",
        "                shape=[num_examples, seq_length],\n",
        "                dtype=tf.int32),\n",
        "        \"label_ids\":\n",
        "            tf.constant(all_label_ids, shape=[num_examples], dtype=tf.int32),\n",
        "    })\n",
        "\n",
        "    if is_training:\n",
        "      d = d.repeat()\n",
        "      d = d.shuffle(buffer_size=100)\n",
        "\n",
        "    d = d.batch(batch_size=batch_size, drop_remainder=drop_remainder)\n",
        "    return d\n",
        "\n",
        "  return input_fn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AHa51RE7I6Az"
      },
      "source": [
        "# Create an input function for training. drop_remainder = True for using TPUs.\n",
        "train_input_fn = input_fn_builder(\n",
        "    features=train_features,\n",
        "    seq_length=MAX_SEQ_LENGTH,\n",
        "    is_training=True,\n",
        "    drop_remainder=False)\n",
        "\n",
        "# Create an input function for validating. drop_remainder = True for using TPUs.\n",
        "val_input_fn = input_fn_builder(\n",
        "    features=val_features,\n",
        "    seq_length=MAX_SEQ_LENGTH,\n",
        "    is_training=False,\n",
        "    drop_remainder=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mI0OWHspW64E"
      },
      "source": [
        "import datetime"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WSrrERU_W67U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc2d2958-a327-433e-d102-017a32d551ee"
      },
      "source": [
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wNyCH35_W-A_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a7af1bf-821d-4f4f-e549-a1686459757d"
      },
      "source": [
        "#Run this If you want to load the model \n",
        "#Loading a specific check point : \n",
        "warm_start = tf.estimator.WarmStartSettings(ckpt_to_initialize_from='/content/drive/MyDrive/MS_Final_Project/Model_checkpoints_CC/model.ckpt-1800.meta')\n",
        "\n",
        "\n",
        "model_fn = model_fn_builder(\n",
        "  num_labels=len(label_list),\n",
        "  learning_rate=LEARNING_RATE,\n",
        "  num_train_steps=num_train_steps,\n",
        "  num_warmup_steps=num_warmup_steps)\n",
        "\n",
        "estimator=tf.estimator.Estimator(model_fn=model_fn,\n",
        "                       config=run_config,\n",
        "                       params={\"batch_size\": BATCH_SIZE},\n",
        "                       warm_start_from=warm_start)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Using config: {'_model_dir': '/content/drive/MyDrive/MS_Final_Project/Model_checkpoints_CC', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 300, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Using config: {'_model_dir': '/content/drive/MyDrive/MS_Final_Project/Model_checkpoints_CC', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 300, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pvk0K1c5W-G1",
        "outputId": "15df9fd2-7d2f-48e2-e479-c107e8ce926f"
      },
      "source": [
        "#Evaluation of the BERT model\n",
        "estimator.evaluate(input_fn=val_input_fn, steps=None)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Done calling model_fn.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Done calling model_fn.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Starting evaluation at 2021-10-08T03:10:16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Starting evaluation at 2021-10-08T03:10:16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Graph was finalized.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Graph was finalized.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Restoring parameters from /content/drive/MyDrive/MS_Final_Project/Model_checkpoints_CC/model.ckpt-1982\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Restoring parameters from /content/drive/MyDrive/MS_Final_Project/Model_checkpoints_CC/model.ckpt-1982\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Running local_init_op.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Running local_init_op.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Done running local_init_op.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Done running local_init_op.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Inference Time : 67.44433s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Inference Time : 67.44433s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Finished evaluation at 2021-10-08-03:11:23\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Finished evaluation at 2021-10-08-03:11:23\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Saving dict for global step 1982: eval_accuracy = 0.8842922, false_negatives = 162.0, false_positives = 121.0, global_step = 1982, loss = 0.38911104, true_negatives = 768.0, true_positives = 6684.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Saving dict for global step 1982: eval_accuracy = 0.8842922, false_negatives = 162.0, false_positives = 121.0, global_step = 1982, loss = 0.38911104, true_negatives = 768.0, true_positives = 6684.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1982: /content/drive/MyDrive/MS_Final_Project/Model_checkpoints_CC/model.ckpt-1982\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1982: /content/drive/MyDrive/MS_Final_Project/Model_checkpoints_CC/model.ckpt-1982\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'eval_accuracy': 0.8842922,\n",
              " 'false_negatives': 162.0,\n",
              " 'false_positives': 121.0,\n",
              " 'global_step': 1982,\n",
              " 'loss': 0.38911104,\n",
              " 'true_negatives': 768.0,\n",
              " 'true_positives': 6684.0}"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MjH1IrCZaSMC"
      },
      "source": [
        "# Create an input function for validating. drop_remainder = True for using TPUs.\n",
        "test_input_fn = input_fn_builder(\n",
        "    features=test_features,\n",
        "    seq_length=MAX_SEQ_LENGTH,\n",
        "    is_training=False,\n",
        "    drop_remainder=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k9Zibu_Lalro"
      },
      "source": [
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OPJbjGZOaNaI",
        "outputId": "e6cb70ee-7785-4a7d-aee4-ee3bc7739b23"
      },
      "source": [
        "estimator.evaluate(input_fn=test_input_fn, steps=None)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'eval_accuracy': 0.83861387,\n",
              " 'false_negatives': 36.0,\n",
              " 'false_positives': 23.0,\n",
              " 'global_step': 1982,\n",
              " 'loss': 0.49866992,\n",
              " 'true_negatives': 107.0,\n",
              " 'true_positives': 844.0}"
            ]
          },
          "metadata": {},
          "execution_count": 170
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mhBuXjQ55f9d"
      },
      "source": [
        "# Extract Embeddings from BERT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTeHqmogZdPQ"
      },
      "source": [
        "def serving_input_receiver_fn():\n",
        "    \"\"\"Serving input_fn that builds features from placeholders\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    tf.estimator.export.ServingInputReceiver\n",
        "    \"\"\"\n",
        "    number = tf.placeholder(dtype=tf.float32, shape=[None, 1], name='number')\n",
        "    receiver_tensors = {'number': number}\n",
        "    features = tf.tile(number, multiples=[1, 2])\n",
        "    return tf.estimator.export.ServingInputReceiver(features, receiver_tensors)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZqu1qKVZdSw"
      },
      "source": [
        "# A method to get predictions\n",
        "def getPrediction(in_sentences, type_output = \"features\"):\n",
        "  #A list to map the actual labels to the predictions\n",
        "  labels = np.unique(train['label'])\n",
        "  input_examples = [InputExample(guid=\"\", text_a = x, text_b = None, label = 0) for x in in_sentences] \n",
        "  #input_features = convert_examples_to_features(input_examples, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
        "  input_features = convert_examples_to_features(tokenizer,input_examples,MAX_SEQ_LENGTH )\n",
        "  #Predicting the classes \n",
        "  predict_input_fn = input_fn_builder(features=input_features, seq_length=MAX_SEQ_LENGTH, is_training=False, drop_remainder=False)\n",
        "  predictions = estimator.predict(predict_input_fn)\n",
        "  if type_output == \"features\":\n",
        "    return [prediction['pooled_output'] for _,prediction in enumerate(predictions) ]\n",
        "  else:\n",
        "    return ([(sentence, prediction['probabilities'],\n",
        "              prediction['labels'], labels[prediction['labels']]) for sentence, prediction in zip(in_sentences, predictions)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_60BrgK5vTB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3823022c-31c5-4e75-d52f-5824d2476a3f"
      },
      "source": [
        "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
        "MAX_SEQ_LENGTH"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "200"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NmBcjVnA5vW3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6596b17-8a0d-47e0-81f7-f9c627e204ab"
      },
      "source": [
        "train_df.shape, val_df.shape , test_df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((30880, 2), (7735, 2), (1010, 2))"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rsm_CEtN5vaH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "597d32d3-3f2b-4d42-b32a-18e9154f5518"
      },
      "source": [
        "tr_emb = np.apply_along_axis(getPrediction, 0,np.array(train_df[DATA_COLUMN]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Converting examples to features: 100%|██████████| 30880/30880 [01:39<00:00, 310.12it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vTZ-uV36Ds-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29ce594d-3d14-447c-d6e1-f31966373dfc"
      },
      "source": [
        "val_emb = np.apply_along_axis(getPrediction, 0,np.array(val_df[DATA_COLUMN]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Converting examples to features: 100%|██████████| 7735/7735 [00:24<00:00, 310.49it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XelnFAAGcmr3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b0cc480-ed6c-4626-fa46-e2ac0943355d"
      },
      "source": [
        "test_emb = np.apply_along_axis(getPrediction, 0,np.array(test_df[DATA_COLUMN]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Converting examples to features: 100%|██████████| 1010/1010 [00:02<00:00, 338.51it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2UyEB1BP6DwG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63026b6d-28c4-4904-be07-35e6a05d994f"
      },
      "source": [
        " tr_emb.shape,val_emb.shape,test_emb.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((30880, 768), (7735, 768), (1010, 768))"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rpOURexG6D11",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "8851e84b-0e3e-456a-dee1-e0cebdb07a62"
      },
      "source": [
        "aux = -1\n",
        "len_l = 0\n",
        "train_x = {}\n",
        "for l, emb in zip(index_l, tr_emb):\n",
        "  if l in train_x.keys():\n",
        "    train_x[l]  =np.vstack([train_x[l], emb])\n",
        "  else:\n",
        "    train_x[l] = [emb]\n",
        "\n",
        "len(train_x.keys())\n",
        "\n",
        "train_l_final = []\n",
        "label_l_final = []\n",
        "for k in train_x.keys():\n",
        "  train_l_final.append(train_x[k])\n",
        "  label_l_final.append(train.loc[k]['label'])\n",
        "\n",
        "df_train = pd.DataFrame({'emb': train_l_final, 'label': label_l_final, })\n",
        "df_train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>emb</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[[-0.021099621, -0.28834894, 0.7219702, 0.3243...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[[-0.94986975, 0.07269567, 0.8704889, 0.950459...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[[-0.97692055, 0.034012984, 0.8985519, 0.97121...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[[-0.33321068, -0.44509885, 0.7722971, 0.52170...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[[0.1334224, -0.16724484, -0.7966242, -0.44695...</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 emb  label\n",
              "0  [[-0.021099621, -0.28834894, 0.7219702, 0.3243...      3\n",
              "1  [[-0.94986975, 0.07269567, 0.8704889, 0.950459...      2\n",
              "2  [[-0.97692055, 0.034012984, 0.8985519, 0.97121...      2\n",
              "3  [[-0.33321068, -0.44509885, 0.7722971, 0.52170...      3\n",
              "4  [[0.1334224, -0.16724484, -0.7966242, -0.44695...      6"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "08Xt-A1I8VTb"
      },
      "source": [
        "def finding_mean(mat):\n",
        "    return np.mean(mat, axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gTOzlu3W8ZBO"
      },
      "source": [
        "df_train['mean_emb'] = df_train['emb'].apply(finding_mean)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ma7LNNTz6EBJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "e01ae7ff-6ad2-42fb-c8d7-6329c804e674"
      },
      "source": [
        "aux = -1\n",
        "len_l = 0\n",
        "val_x = {}\n",
        "\n",
        "for l, emb in zip(val_index_l, val_emb):\n",
        "  if l in val_x.keys():\n",
        "    val_x[l]  =np.vstack([val_x[l], emb])\n",
        "  else:\n",
        "    val_x[l] = [emb]\n",
        "\n",
        "\n",
        "val_l_final = []\n",
        "vlabel_l_final = []\n",
        "for k in val_x.keys():\n",
        "  val_l_final.append(val_x[k])\n",
        "  vlabel_l_final.append(val.loc[k]['label'])\n",
        "\n",
        "df_val = pd.DataFrame({'emb': val_l_final, 'label': vlabel_l_final})\n",
        "df_val.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>emb</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[[-0.48734725, -0.25630832, 0.68144184, 0.2679...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[[0.91885906, 0.18151335, 0.60991126, -0.96630...</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[[0.59430116, 0.55512154, -0.65703773, -0.2662...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[[-0.89417297, -0.046206344, 0.8854584, 0.9049...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[[0.84196603, 0.4628314, -0.8256536, -0.729129...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 emb  label\n",
              "0  [[-0.48734725, -0.25630832, 0.68144184, 0.2679...      0\n",
              "1  [[0.91885906, 0.18151335, 0.60991126, -0.96630...      8\n",
              "2  [[0.59430116, 0.55512154, -0.65703773, -0.2662...      4\n",
              "3  [[-0.89417297, -0.046206344, 0.8854584, 0.9049...      2\n",
              "4  [[0.84196603, 0.4628314, -0.8256536, -0.729129...      4"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EbtNQaUN8fcf"
      },
      "source": [
        "df_val['mean_emb'] = df_val['emb'].apply(finding_mean)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6r60G3NC8fov",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "88ba20aa-a363-4b22-d2cf-6a4a2a700d12"
      },
      "source": [
        "df_val.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>emb</th>\n",
              "      <th>label</th>\n",
              "      <th>mean_emb</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[[-0.48734725, -0.25630832, 0.68144184, 0.2679...</td>\n",
              "      <td>0</td>\n",
              "      <td>[-0.62836844, -0.36085394, 0.6531887, 0.350620...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[[0.91885906, 0.18151335, 0.60991126, -0.96630...</td>\n",
              "      <td>8</td>\n",
              "      <td>[0.91885906, 0.18151335, 0.60991126, -0.966300...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[[0.59430116, 0.55512154, -0.65703773, -0.2662...</td>\n",
              "      <td>4</td>\n",
              "      <td>[0.27127713, 0.12112405, -0.39737955, 0.003545...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[[-0.89417297, -0.046206344, 0.8854584, 0.9049...</td>\n",
              "      <td>2</td>\n",
              "      <td>[-0.9434062, -0.0002270646, 0.8144107, 0.94089...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[[0.84196603, 0.4628314, -0.8256536, -0.729129...</td>\n",
              "      <td>4</td>\n",
              "      <td>[0.74197656, 0.44996598, -0.87471235, -0.54836...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 emb  ...                                           mean_emb\n",
              "0  [[-0.48734725, -0.25630832, 0.68144184, 0.2679...  ...  [-0.62836844, -0.36085394, 0.6531887, 0.350620...\n",
              "1  [[0.91885906, 0.18151335, 0.60991126, -0.96630...  ...  [0.91885906, 0.18151335, 0.60991126, -0.966300...\n",
              "2  [[0.59430116, 0.55512154, -0.65703773, -0.2662...  ...  [0.27127713, 0.12112405, -0.39737955, 0.003545...\n",
              "3  [[-0.89417297, -0.046206344, 0.8854584, 0.9049...  ...  [-0.9434062, -0.0002270646, 0.8144107, 0.94089...\n",
              "4  [[0.84196603, 0.4628314, -0.8256536, -0.729129...  ...  [0.74197656, 0.44996598, -0.87471235, -0.54836...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zZ-QWHvhnHo_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "c1d4a9a2-c0dd-4693-dd50-652b77ca7b5e"
      },
      "source": [
        "aux = -1\n",
        "len_l = 0\n",
        "test_x = {}\n",
        "\n",
        "for l, emb in zip(test_index_l, test_emb):\n",
        "  if l in test_x.keys():\n",
        "    test_x[l]  =np.vstack([test_x[l], emb])\n",
        "  else:\n",
        "    test_x[l] = [emb]\n",
        "\n",
        "\n",
        "test_l_final = []\n",
        "telabel_l_final = []\n",
        "for k in test_x.keys():\n",
        "  test_l_final.append(test_x[k])\n",
        "  telabel_l_final.append(test_set.loc[k]['label'])\n",
        "\n",
        "df_test = pd.DataFrame({'emb': test_l_final, 'label': telabel_l_final})\n",
        "df_test.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>emb</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[[0.9054842, -0.43966478, 0.48783314, -0.93049...</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[[0.2676942, 0.35215834, 0.32371885, -0.642981...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[[-0.09947222, -0.087502845, -0.7776193, -0.34...</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[[-0.46511343, -0.11849337, -0.79615223, 0.017...</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[[-0.09688268, -0.13573642, -0.9071443, -0.282...</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 emb  label\n",
              "0  [[0.9054842, -0.43966478, 0.48783314, -0.93049...      9\n",
              "1  [[0.2676942, 0.35215834, 0.32371885, -0.642981...      1\n",
              "2  [[-0.09947222, -0.087502845, -0.7776193, -0.34...      6\n",
              "3  [[-0.46511343, -0.11849337, -0.79615223, 0.017...      6\n",
              "4  [[-0.09688268, -0.13573642, -0.9071443, -0.282...      6"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "InmeWoW88mPL"
      },
      "source": [
        "df_test['mean_emb'] = df_test['emb'].apply(finding_mean)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YuEYH7W98oDx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "a928ad86-38b3-476a-ad56-8d07d5b8aa29"
      },
      "source": [
        "df_test.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>emb</th>\n",
              "      <th>label</th>\n",
              "      <th>mean_emb</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[[0.9054842, -0.43966478, 0.48783314, -0.93049...</td>\n",
              "      <td>9</td>\n",
              "      <td>[0.86915934, -0.5181881, 0.22399111, -0.927366...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[[0.2676942, 0.35215834, 0.32371885, -0.642981...</td>\n",
              "      <td>1</td>\n",
              "      <td>[0.37092346, 0.26684362, 0.101669595, -0.69861...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[[-0.09947222, -0.087502845, -0.7776193, -0.34...</td>\n",
              "      <td>6</td>\n",
              "      <td>[-0.12090798, -0.16979125, -0.78995925, -0.213...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[[-0.46511343, -0.11849337, -0.79615223, 0.017...</td>\n",
              "      <td>6</td>\n",
              "      <td>[-0.14204708, -0.089664616, -0.8603732, -0.125...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[[-0.09688268, -0.13573642, -0.9071443, -0.282...</td>\n",
              "      <td>6</td>\n",
              "      <td>[-0.09876074, -0.18477602, -0.8435634, -0.3983...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 emb  ...                                           mean_emb\n",
              "0  [[0.9054842, -0.43966478, 0.48783314, -0.93049...  ...  [0.86915934, -0.5181881, 0.22399111, -0.927366...\n",
              "1  [[0.2676942, 0.35215834, 0.32371885, -0.642981...  ...  [0.37092346, 0.26684362, 0.101669595, -0.69861...\n",
              "2  [[-0.09947222, -0.087502845, -0.7776193, -0.34...  ...  [-0.12090798, -0.16979125, -0.78995925, -0.213...\n",
              "3  [[-0.46511343, -0.11849337, -0.79615223, 0.017...  ...  [-0.14204708, -0.089664616, -0.8603732, -0.125...\n",
              "4  [[-0.09688268, -0.13573642, -0.9071443, -0.282...  ...  [-0.09876074, -0.18477602, -0.8435634, -0.3983...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dAQjJPEn80NS"
      },
      "source": [
        "# import pickle\n",
        "\n",
        "# pickle_out = open(\"/content/drive/MyDrive/MS_Final_Project/df_train_cc_count5.pickle\",\"wb\")\n",
        "# pickle.dump(df_train, pickle_out)\n",
        "# pickle_out.close()\n",
        "\n",
        "# pickle_out = open(\"/content/drive/MyDrive/MS_Final_Project/df_val_cc_count5.pickle\",\"wb\")\n",
        "# pickle.dump(df_val, pickle_out)\n",
        "# pickle_out.close()\n",
        "\n",
        "# pickle_out = open(\"/content/drive/MyDrive/MS_Final_Project/df_test_cc_count5.pickle\",\"wb\")\n",
        "# pickle.dump(df_test, pickle_out)\n",
        "# pickle_out.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yec5McSF-ghJ"
      },
      "source": [
        "pickle_in = open(\"/content/drive/MyDrive/MS_Final_Project/df_train_cc_count5.pickle\",\"rb\")\n",
        "df_train_pickle1 = pickle.load(pickle_in)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "vr5xAgoV-yXf",
        "outputId": "485224f0-b7f2-4741-bb46-cec2f4df2584"
      },
      "source": [
        "df_train_pickle1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>emb</th>\n",
              "      <th>label</th>\n",
              "      <th>mean_emb</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[[-0.021099621, -0.28834894, 0.7219702, 0.3243...</td>\n",
              "      <td>3</td>\n",
              "      <td>[-0.31734654, -0.2424916, 0.63371956, 0.544734...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[[-0.94986975, 0.07269567, 0.8704889, 0.950459...</td>\n",
              "      <td>2</td>\n",
              "      <td>[-0.92828494, 0.183393, 0.8550927, 0.9233754, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[[-0.97692055, 0.034012984, 0.8985519, 0.97121...</td>\n",
              "      <td>2</td>\n",
              "      <td>[-0.97692055, 0.034012984, 0.8985519, 0.971216...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[[-0.33321068, -0.44509885, 0.7722971, 0.52170...</td>\n",
              "      <td>3</td>\n",
              "      <td>[-0.33321068, -0.44509885, 0.7722971, 0.521708...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[[0.1334224, -0.16724484, -0.7966242, -0.44695...</td>\n",
              "      <td>6</td>\n",
              "      <td>[-0.3031048, -0.41733286, -0.82505804, -0.2265...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13547</th>\n",
              "      <td>[[0.046362247, -0.035511155, -0.8277228, -0.45...</td>\n",
              "      <td>6</td>\n",
              "      <td>[0.20709851, -0.11711824, -0.772329, -0.472510...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13548</th>\n",
              "      <td>[[-0.910325, 0.2355118, 0.897265, 0.9133836, -...</td>\n",
              "      <td>2</td>\n",
              "      <td>[-0.8838366, 0.19539505, 0.8418225, 0.8763018,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13549</th>\n",
              "      <td>[[0.5068917, -0.039287187, -0.9189707, -0.2104...</td>\n",
              "      <td>4</td>\n",
              "      <td>[0.6690841, 0.31198674, -0.7114719, -0.4333441...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13550</th>\n",
              "      <td>[[-0.40635964, -0.45109355, 0.8118932, 0.54926...</td>\n",
              "      <td>3</td>\n",
              "      <td>[-0.17363006, -0.41950807, 0.7430628, 0.339043...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13551</th>\n",
              "      <td>[[-0.6468596, -0.7702212, -0.29160282, 0.34270...</td>\n",
              "      <td>3</td>\n",
              "      <td>[-0.6415425, -0.81177425, 0.011334375, 0.27554...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>13552 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                     emb  ...                                           mean_emb\n",
              "0      [[-0.021099621, -0.28834894, 0.7219702, 0.3243...  ...  [-0.31734654, -0.2424916, 0.63371956, 0.544734...\n",
              "1      [[-0.94986975, 0.07269567, 0.8704889, 0.950459...  ...  [-0.92828494, 0.183393, 0.8550927, 0.9233754, ...\n",
              "2      [[-0.97692055, 0.034012984, 0.8985519, 0.97121...  ...  [-0.97692055, 0.034012984, 0.8985519, 0.971216...\n",
              "3      [[-0.33321068, -0.44509885, 0.7722971, 0.52170...  ...  [-0.33321068, -0.44509885, 0.7722971, 0.521708...\n",
              "4      [[0.1334224, -0.16724484, -0.7966242, -0.44695...  ...  [-0.3031048, -0.41733286, -0.82505804, -0.2265...\n",
              "...                                                  ...  ...                                                ...\n",
              "13547  [[0.046362247, -0.035511155, -0.8277228, -0.45...  ...  [0.20709851, -0.11711824, -0.772329, -0.472510...\n",
              "13548  [[-0.910325, 0.2355118, 0.897265, 0.9133836, -...  ...  [-0.8838366, 0.19539505, 0.8418225, 0.8763018,...\n",
              "13549  [[0.5068917, -0.039287187, -0.9189707, -0.2104...  ...  [0.6690841, 0.31198674, -0.7114719, -0.4333441...\n",
              "13550  [[-0.40635964, -0.45109355, 0.8118932, 0.54926...  ...  [-0.17363006, -0.41950807, 0.7430628, 0.339043...\n",
              "13551  [[-0.6468596, -0.7702212, -0.29160282, 0.34270...  ...  [-0.6415425, -0.81177425, 0.011334375, 0.27554...\n",
              "\n",
              "[13552 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AAxFAvPTEB4u"
      },
      "source": [
        "#creating the input for the transformer\n",
        "x_train=[]\n",
        "y_train=[]\n",
        "for i in range(df_train.shape[0]):\n",
        "  x_train.append(df_train[\"mean_emb\"][i])\n",
        "  y_train.append(df_train[\"label\"][i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3GuRff91EB6_"
      },
      "source": [
        "x_tr = np.array(x_train)\n",
        "y_tr=np.array(y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJg6BxE8ECCK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "809d287f-d59d-454b-f1eb-1504f4345ebc"
      },
      "source": [
        "x_tr.shape, y_tr.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((13552, 768), (13552,))"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Fr1weEgECEU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0af699c-9710-4468-d9ea-6c8361b5a7a8"
      },
      "source": [
        "#creating the validation input \n",
        "x_val=[]\n",
        "y_val=[]\n",
        "for i in range(df_val.shape[0]):\n",
        "  x_val.append(df_val[\"mean_emb\"][i])\n",
        "  y_val.append(df_val[\"label\"][i])\n",
        "\n",
        "x_va = np.array(x_val)\n",
        "y_va=np.array(y_val)\n",
        "\n",
        "x_va.shape, y_va.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((3388, 768), (3388,))"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rt_L20xgECHh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a45eca7d-9a84-43b8-df25-3fc0bd93d648"
      },
      "source": [
        "#creating the test input \n",
        "x_test=[]\n",
        "y_test=[]\n",
        "for i in range(df_test.shape[0]):\n",
        "  x_test.append(df_test[\"mean_emb\"][i])\n",
        "  y_test.append(df_test[\"label\"][i])\n",
        "\n",
        "x_te = np.array(x_test)\n",
        "y_te=np.array(y_test)\n",
        "\n",
        "x_te.shape, y_te.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((202, 768), (202,))"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VwZYsz2VGfzh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "500d50ce-070a-431c-d112-c8a1d23cc968"
      },
      "source": [
        "#creating the validation input \n",
        "x_e_tr=[]\n",
        "y_e_tr=[]\n",
        "for i in range(df_train.shape[0]):\n",
        "  x_e_tr.append(df_train[\"emb\"][i])\n",
        "  y_e_tr.append(df_train[\"label\"][i])\n",
        "\n",
        "x_emb_tr = np.array(x_e_tr)\n",
        "y_emb_tr=np.array(y_e_tr)\n",
        "\n",
        "x_emb_tr.shape, y_emb_tr.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((13552,), (13552,))"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YG_P1rUaHLek",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0253841-e651-4468-c0ed-32c327d1745f"
      },
      "source": [
        "df_train[\"emb\"][0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.0211  , -0.288349,  0.72197 ,  0.324376, ...,  0.802411,  0.902796, -0.522767, -0.101945],\n",
              "       [-0.613593, -0.196634,  0.545469,  0.765092, ...,  0.781981,  0.731322, -0.640408,  0.276129]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y10w4cAFHR_0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63071b4f-8620-4c6e-a652-9289df6a9e78"
      },
      "source": [
        "type(x_emb_tr[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kvHh_ZA2F-Jh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72ac5916-079a-48af-c0e9-628f1dca4c85"
      },
      "source": [
        "#creating the validation input \n",
        "x_e_val=[]\n",
        "y_e_val=[]\n",
        "for i in range(df_val.shape[0]):\n",
        "  x_e_val.append(df_val[\"emb\"][i])\n",
        "  y_e_val.append(df_val[\"label\"][i])\n",
        "\n",
        "x_emb_val = np.array(x_e_val)\n",
        "y_emb_val=np.array(y_e_val)\n",
        "\n",
        "x_emb_val.shape, y_emb_val.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((3388,), (3388,))"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "crzKglP9F-NV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1ae3fc4-3f51-4317-dfa9-ae5551530502"
      },
      "source": [
        "#creating the validation input \n",
        "x_e_test=[]\n",
        "y_e_test=[]\n",
        "for i in range(df_test.shape[0]):\n",
        "  x_e_test.append(df_test[\"emb\"][i])\n",
        "  y_e_test.append(df_test[\"label\"][i])\n",
        "\n",
        "x_emb_test = np.array(x_e_test)\n",
        "y_emb_test=np.array(y_e_test)\n",
        "\n",
        "x_emb_test.shape, y_emb_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((202, 5, 768), (202,))"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQLxgV51H4eN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9f06055-1c78-4f42-a4a4-184a4a3e131b"
      },
      "source": [
        "x_emb_test[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.905484, -0.439665,  0.487833, -0.930498, ...,  0.112375,  0.137263, -0.564621, -0.94157 ],\n",
              "       [ 0.888559, -0.55981 ,  0.310729, -0.926052, ...,  0.522132, -0.091857, -0.516601, -0.920653],\n",
              "       [ 0.817395, -0.587691,  0.022902, -0.899876, ...,  0.502195, -0.195852, -0.613516, -0.917648],\n",
              "       [ 0.830759, -0.514598, -0.549505, -0.924031, ...,  0.668297, -0.828999, -0.413538, -0.658639],\n",
              "       [ 0.903599, -0.489176,  0.847997, -0.956377, ...,  0.537001,  0.373665, -0.429996, -0.934402]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VULdNfW-NF1E"
      },
      "source": [
        "#Masking the input for same length \n",
        "num_features=768\n",
        "def input_generator(df):\n",
        "    x_list= df['emb'].to_list()\n",
        "    y_list= df.label.to_list()\n",
        "    timesteps = len(max(df['emb'].to_list(), key=len))\n",
        "    x_train= np.full((df['emb'].shape[0], timesteps, num_features), -99.)\n",
        "    y_train = np.zeros((df['emb'].shape[0],  1))\n",
        "    for b in range(len(x_list)):\n",
        "        x_train[b, 0:len(x_list[b]), :] = x_list[b]\n",
        "        y_train[b]=y_list[b]\n",
        "    return x_train, y_train\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9CL7nSeONF41",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3fff45fb-6a43-4910-8066-d8928ffaf719"
      },
      "source": [
        "x_train_new,y_train_new=input_generator(df_train)\n",
        "x_train_new.shape, y_train_new.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((13552, 4, 768), (13552, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-p_6wrnUq20C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15d37d82-8365-4bc7-a78d-5d2a3e15171d"
      },
      "source": [
        "x_val_new,y_val_new=input_generator(df_val)\n",
        "x_val_new.shape, y_val_new.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((3388, 4, 768), (3388, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4jjLFxtFEMn2"
      },
      "source": [
        "# Transformer Model Creation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vEuPjsHsJ_cd"
      },
      "source": [
        "# import tensorflow.compat.v1 as tf\n",
        "# tf.disable_v2_behavior()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ujV9wjnGtel-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e96a964-3c73-48c3-b923-98d5c0a3efae"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L4YWac3eECNE"
      },
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nPNEhHPhECPW"
      },
      "source": [
        "\n",
        "class TransformerBlock(layers.Layer):\n",
        "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
        "        super(TransformerBlock, self).__init__()\n",
        "        self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.ffn = keras.Sequential(\n",
        "            [layers.Dense(ff_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n",
        "        )\n",
        "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.dropout1 = layers.Dropout(rate)\n",
        "        self.dropout2 = layers.Dropout(rate)\n",
        "\n",
        "    def call(self, inputs, training):\n",
        "        attn_output = self.att(inputs, inputs)\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        out1 = self.layernorm1(inputs + attn_output)\n",
        "        ffn_output = self.ffn(out1)\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\n",
        "        return self.layernorm2(out1 + ffn_output)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oaY8TCx1ECSk"
      },
      "source": [
        "\n",
        "class TokenAndPositionEmbedding(layers.Layer):\n",
        "    def __init__(self, maxlen, vocab_size, embed_dim):\n",
        "        super(TokenAndPositionEmbedding, self).__init__()\n",
        "        #self.token_emb = layers.Embedding(input_dim=vocab_size, output_dim=embed_dim)\n",
        "        self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=embed_dim)\n",
        "\n",
        "    def call(self, x):\n",
        "        maxlen = tf.shape(x)[-1]\n",
        "        positions = tf.range(start=0, limit=maxlen, delta=1)\n",
        "        positions = self.pos_emb(positions)\n",
        "        print(positions)\n",
        "        #x = self.token_emb(x)\n",
        "        print(x)\n",
        "        return x + positions\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WF8P5ZeeFc24"
      },
      "source": [
        "df_train['emb'].shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LGsLtaddJEyE"
      },
      "source": [
        "vocab_size = 30  # Only consider the top 20k words\n",
        "maxlen = 4  # Only consider the first 200 words of each movie review"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7vGBiRyvECUz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "533110ed-9319-4864-9570-deaf4a56a1b9"
      },
      "source": [
        "\n",
        "embed_dim = 768  # Embedding size for each token\n",
        "num_heads = 2  # Number of attention heads\n",
        "ff_dim = 32  # Hidden layer size in feed forward network inside transformer\n",
        "\n",
        "inputs = layers.Input(shape=(None,768,))\n",
        "embedding_layer = TokenAndPositionEmbedding(maxlen, vocab_size, embed_dim)\n",
        "x = embedding_layer(inputs)\n",
        "x = inputs\n",
        "transformer_block = TransformerBlock(embed_dim, num_heads, ff_dim)\n",
        "x = transformer_block(x,True)\n",
        "x = layers.GlobalAveragePooling1D()(x)\n",
        "x = layers.Dropout(0.1)(x)\n",
        "x = layers.Dense(20, activation=\"relu\")(x)\n",
        "x = layers.Dropout(0.1)(x)\n",
        "outputs = layers.Dense(10, activation=\"softmax\")(x)\n",
        "\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor(\"token_and_position_embedding_2/embedding_2/embedding_lookup/Identity_1:0\", shape=(?, 768), dtype=float32)\n",
            "Tensor(\"input_3:0\", shape=(?, ?, 768), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pkzSHzJgJRwV",
        "outputId": "044753d0-fdc1-442a-deea-b522c929ab7b"
      },
      "source": [
        "x_emb_tr[0].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 768)"
            ]
          },
          "metadata": {},
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fr7VUJO5sL_k",
        "outputId": "b80eeba0-0304-4d7f-f3f2-afc187bd2f06"
      },
      "source": [
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B7bsikdnAqGt",
        "outputId": "77d5c4bd-d39f-4380-f148-90b4787c30ff"
      },
      "source": [
        "x_train_new.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(13552, 4, 768)"
            ]
          },
          "metadata": {},
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DfNFj498A4yy",
        "outputId": "bf5fba5b-b50f-499d-ac82-883b4d565f9f"
      },
      "source": [
        "print(tf.test.gpu_device_name())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/device:GPU:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EvrHprKNECYB",
        "outputId": "4c352238-0691-43da-88c3-72581c75f68d"
      },
      "source": [
        "model.compile(\"adam\", \"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "model.fit(x_train_new, y_train_new, batch_size=32, epochs=40, validation_data=(x_val_new, y_val_new))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train on 13552 samples, validate on 3388 samples\n",
            "Epoch 1/40\n",
            "13312/13552 [============================>.] - ETA: 0s - loss: 0.6208 - acc: 0.8098"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:2426: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13552/13552 [==============================] - 3s 239us/sample - loss: 0.6209 - acc: 0.8097 - val_loss: 0.6674 - val_acc: 0.7999\n",
            "Epoch 2/40\n",
            "13552/13552 [==============================] - 3s 206us/sample - loss: 0.6647 - acc: 0.8000 - val_loss: 0.6780 - val_acc: 0.7931\n",
            "Epoch 3/40\n",
            "13552/13552 [==============================] - 3s 206us/sample - loss: 0.6643 - acc: 0.7981 - val_loss: 0.6574 - val_acc: 0.8037\n",
            "Epoch 4/40\n",
            "13552/13552 [==============================] - 3s 204us/sample - loss: 0.7473 - acc: 0.7830 - val_loss: 0.6877 - val_acc: 0.7946\n",
            "Epoch 5/40\n",
            "13552/13552 [==============================] - 3s 203us/sample - loss: 0.6128 - acc: 0.8212 - val_loss: 0.4582 - val_acc: 0.8843\n",
            "Epoch 6/40\n",
            "13552/13552 [==============================] - 3s 204us/sample - loss: 0.4712 - acc: 0.8675 - val_loss: 0.4866 - val_acc: 0.8439\n",
            "Epoch 7/40\n",
            "13552/13552 [==============================] - 3s 204us/sample - loss: 0.4870 - acc: 0.8393 - val_loss: 0.4805 - val_acc: 0.8430\n",
            "Epoch 8/40\n",
            "13552/13552 [==============================] - 3s 204us/sample - loss: 0.4817 - acc: 0.8370 - val_loss: 0.4925 - val_acc: 0.8406\n",
            "Epoch 9/40\n",
            "13552/13552 [==============================] - 3s 204us/sample - loss: 0.4891 - acc: 0.8350 - val_loss: 0.4806 - val_acc: 0.8424\n",
            "Epoch 10/40\n",
            "13552/13552 [==============================] - 3s 203us/sample - loss: 0.4892 - acc: 0.8360 - val_loss: 0.4919 - val_acc: 0.8415\n",
            "Epoch 11/40\n",
            "13552/13552 [==============================] - 3s 204us/sample - loss: 0.4858 - acc: 0.8366 - val_loss: 0.4947 - val_acc: 0.8365\n",
            "Epoch 12/40\n",
            "13552/13552 [==============================] - 3s 204us/sample - loss: 0.4987 - acc: 0.8301 - val_loss: 0.5199 - val_acc: 0.8229\n",
            "Epoch 13/40\n",
            "13552/13552 [==============================] - 3s 204us/sample - loss: 0.5182 - acc: 0.8293 - val_loss: 0.4973 - val_acc: 0.8456\n",
            "Epoch 14/40\n",
            "13552/13552 [==============================] - 3s 204us/sample - loss: 0.4837 - acc: 0.8422 - val_loss: 0.4855 - val_acc: 0.8492\n",
            "Epoch 15/40\n",
            "13552/13552 [==============================] - 3s 203us/sample - loss: 0.4455 - acc: 0.8514 - val_loss: 0.4538 - val_acc: 0.8551\n",
            "Epoch 16/40\n",
            "13552/13552 [==============================] - 3s 208us/sample - loss: 0.4418 - acc: 0.8539 - val_loss: 0.4427 - val_acc: 0.8619\n",
            "Epoch 17/40\n",
            "13552/13552 [==============================] - 3s 211us/sample - loss: 0.4274 - acc: 0.8605 - val_loss: 0.4270 - val_acc: 0.8707\n",
            "Epoch 18/40\n",
            "13552/13552 [==============================] - 3s 209us/sample - loss: 0.4185 - acc: 0.8683 - val_loss: 0.4024 - val_acc: 0.8766\n",
            "Epoch 19/40\n",
            "13552/13552 [==============================] - 3s 208us/sample - loss: 0.4040 - acc: 0.8723 - val_loss: 0.4007 - val_acc: 0.8811\n",
            "Epoch 20/40\n",
            "13552/13552 [==============================] - 3s 205us/sample - loss: 0.3989 - acc: 0.8725 - val_loss: 0.4093 - val_acc: 0.8672\n",
            "Epoch 21/40\n",
            "13552/13552 [==============================] - 3s 202us/sample - loss: 0.3974 - acc: 0.8751 - val_loss: 0.3954 - val_acc: 0.8740\n",
            "Epoch 22/40\n",
            "13552/13552 [==============================] - 3s 202us/sample - loss: 0.3937 - acc: 0.8754 - val_loss: 0.3740 - val_acc: 0.8799\n",
            "Epoch 23/40\n",
            "13552/13552 [==============================] - 3s 204us/sample - loss: 0.3691 - acc: 0.8865 - val_loss: 0.3724 - val_acc: 0.8816\n",
            "Epoch 24/40\n",
            "13552/13552 [==============================] - 3s 202us/sample - loss: 0.3661 - acc: 0.8841 - val_loss: 0.3727 - val_acc: 0.8843\n",
            "Epoch 25/40\n",
            "13552/13552 [==============================] - 3s 202us/sample - loss: 0.3608 - acc: 0.8854 - val_loss: 0.3757 - val_acc: 0.8852\n",
            "Epoch 26/40\n",
            "13552/13552 [==============================] - 3s 202us/sample - loss: 0.3805 - acc: 0.8794 - val_loss: 0.4139 - val_acc: 0.8725\n",
            "Epoch 27/40\n",
            "13552/13552 [==============================] - 3s 202us/sample - loss: 0.4182 - acc: 0.8645 - val_loss: 0.4070 - val_acc: 0.8743\n",
            "Epoch 28/40\n",
            "13552/13552 [==============================] - 3s 203us/sample - loss: 0.4157 - acc: 0.8675 - val_loss: 0.3999 - val_acc: 0.8754\n",
            "Epoch 29/40\n",
            "13552/13552 [==============================] - 3s 202us/sample - loss: 0.4087 - acc: 0.8692 - val_loss: 0.4042 - val_acc: 0.8749\n",
            "Epoch 30/40\n",
            "13552/13552 [==============================] - 3s 203us/sample - loss: 0.4081 - acc: 0.8695 - val_loss: 0.4139 - val_acc: 0.8660\n",
            "Epoch 31/40\n",
            "13552/13552 [==============================] - 3s 203us/sample - loss: 0.4085 - acc: 0.8697 - val_loss: 0.4026 - val_acc: 0.8692\n",
            "Epoch 32/40\n",
            "13552/13552 [==============================] - 3s 201us/sample - loss: 0.4071 - acc: 0.8713 - val_loss: 0.3921 - val_acc: 0.8790\n",
            "Epoch 33/40\n",
            "13552/13552 [==============================] - 3s 203us/sample - loss: 0.4126 - acc: 0.8636 - val_loss: 0.4357 - val_acc: 0.8619\n",
            "Epoch 34/40\n",
            "13552/13552 [==============================] - 3s 202us/sample - loss: 0.4286 - acc: 0.8555 - val_loss: 0.4297 - val_acc: 0.8610\n",
            "Epoch 35/40\n",
            "13552/13552 [==============================] - 3s 205us/sample - loss: 0.4287 - acc: 0.8540 - val_loss: 0.4308 - val_acc: 0.8568\n",
            "Epoch 36/40\n",
            "13552/13552 [==============================] - 3s 202us/sample - loss: 0.4300 - acc: 0.8558 - val_loss: 0.4375 - val_acc: 0.8586\n",
            "Epoch 37/40\n",
            "13552/13552 [==============================] - 3s 203us/sample - loss: 0.3703 - acc: 0.8867 - val_loss: 0.3365 - val_acc: 0.9097\n",
            "Epoch 38/40\n",
            "13552/13552 [==============================] - 3s 202us/sample - loss: 0.3145 - acc: 0.9129 - val_loss: 0.3346 - val_acc: 0.9109\n",
            "Epoch 39/40\n",
            "13552/13552 [==============================] - 3s 201us/sample - loss: 0.3113 - acc: 0.9120 - val_loss: 0.3288 - val_acc: 0.9103\n",
            "Epoch 40/40\n",
            "13552/13552 [==============================] - 3s 204us/sample - loss: 0.3085 - acc: 0.9140 - val_loss: 0.3284 - val_acc: 0.9050\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fba51084c10>"
            ]
          },
          "metadata": {},
          "execution_count": 159
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eIQlsqtbNian",
        "outputId": "dac8ca65-3b57-4169-e9b0-988917c0e127"
      },
      "source": [
        "x_test_new,y_test_new=input_generator(df_test)\n",
        "x_test_new.shape, y_test_new.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((202, 5, 768), (202, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 160
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Osm4n2r4ECaR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "711be08c-cb3f-466e-dfdc-501c102b7fc3"
      },
      "source": [
        "y_proba=model.predict(x_test_new)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:2426: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SmgGLck-N3gU",
        "outputId": "ccd356fa-d71c-4ab4-e8d8-28a360fc5e02"
      },
      "source": [
        "y_proba"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[9.027434e-08, 3.889851e-05, 3.657653e-12, 2.174903e-05, ..., 2.652809e-03, 2.144997e-04, 9.700734e-05,\n",
              "        9.890404e-01],\n",
              "       [2.792854e-07, 9.998766e-01, 7.441630e-08, 9.730267e-06, ..., 1.914151e-10, 1.179892e-06, 2.513387e-06,\n",
              "        3.028690e-07],\n",
              "       [3.537511e-04, 3.276363e-05, 1.382831e-05, 1.975912e-07, ..., 9.977552e-01, 1.103436e-04, 3.281945e-07,\n",
              "        1.504454e-10],\n",
              "       [1.415591e-03, 3.978645e-04, 3.642303e-05, 2.909844e-05, ..., 9.548303e-01, 1.811554e-03, 7.091745e-05,\n",
              "        4.616264e-08],\n",
              "       ...,\n",
              "       [2.234897e-05, 5.011218e-05, 1.428910e-06, 2.057262e-04, ..., 9.927182e-01, 4.368439e-06, 4.762219e-07,\n",
              "        3.297347e-10],\n",
              "       [2.654622e-03, 4.861393e-04, 8.883431e-05, 2.187428e-06, ..., 9.863436e-01, 8.217194e-04, 2.560095e-05,\n",
              "        1.009410e-08],\n",
              "       [2.371457e-03, 4.260127e-04, 7.784545e-01, 9.026015e-03, ..., 4.324513e-08, 3.308851e-05, 5.799739e-06,\n",
              "        1.303655e-07],\n",
              "       [3.832221e-03, 8.989450e-07, 7.370576e-05, 2.411708e-14, ..., 9.503776e-01, 1.353220e-02, 2.243019e-08,\n",
              "        1.640288e-10]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 162
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JqIBkms2NWcM"
      },
      "source": [
        "y_pred=[]\n",
        "for i in y_proba:\n",
        "    max_index_row = np.argmax(i, axis=0)\n",
        "    y_pred.append(max_index_row)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DXGQ-mvQECdi",
        "outputId": "e5629f18-b93b-433d-c40e-82cfa8e3e4b5"
      },
      "source": [
        "#Evaluating Model Performance by creating confusion matrix and classification report\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "print('Confusion Matrix')\n",
        "print(confusion_matrix(y_pred, df_test['label']))\n",
        "print('Classification Report')\n",
        "print(classification_report(y_pred, df_test['label']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix\n",
            "[[23  0  2  0 ...  1  0  0  0]\n",
            " [ 0 15  2  0 ...  0  0  2  0]\n",
            " [ 2  0 23  0 ...  0  0  0  0]\n",
            " [ 0  0  0  9 ...  0  0  0  0]\n",
            " ...\n",
            " [ 0  0  0  0 ...  1  0  0  0]\n",
            " [ 1  2  0  0 ...  0 83  0  0]\n",
            " [ 0  0  0  0 ...  0  0  0  0]\n",
            " [ 0  0  0  0 ...  0  0  0  6]]\n",
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.85      0.87        27\n",
            "           1       0.88      0.75      0.81        20\n",
            "           2       0.77      0.92      0.84        25\n",
            "           3       0.90      0.90      0.90        10\n",
            "           4       0.88      0.78      0.82        27\n",
            "           5       0.50      1.00      0.67         1\n",
            "           6       1.00      0.97      0.98        86\n",
            "           8       0.00      0.00      0.00         0\n",
            "           9       0.86      1.00      0.92         6\n",
            "\n",
            "    accuracy                           0.90       202\n",
            "   macro avg       0.74      0.80      0.76       202\n",
            "weighted avg       0.92      0.90      0.90       202\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q88omhCrOAC_",
        "outputId": "abada5ac-d3e3-4beb-e28b-4ec723204766"
      },
      "source": [
        "mat = confusion_matrix(y_pred, df_test['label'])\n",
        "\n",
        "diag = np.diagonal(mat)\n",
        "print('No of correctly identified labels :',sum(diag))\n",
        "print('No of misclassified samples : ',sum(sum(mat))-sum(diag))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No of correctly identified labels : 181\n",
            "No of misclassified samples :  21\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4OHeBi0sECfz"
      },
      "source": [
        "y_proba=model.predict(x_te)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "okIT4TSQNWZq",
        "outputId": "a5be5b10-56d2-4100-97ea-ad1febf72099"
      },
      "source": [
        "y_proba"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.111036, 0.060999, 0.134507, 0.118398, ..., 0.330741, 0.002619, 0.005043, 0.037773],\n",
              "       [0.111038, 0.06101 , 0.134523, 0.118377, ..., 0.330754, 0.00262 , 0.005043, 0.037784],\n",
              "       [0.111036, 0.060999, 0.134507, 0.118398, ..., 0.330741, 0.002619, 0.005043, 0.037773],\n",
              "       [0.111036, 0.060999, 0.134507, 0.118398, ..., 0.330741, 0.002619, 0.005043, 0.037773],\n",
              "       ...,\n",
              "       [0.111036, 0.060999, 0.134507, 0.118398, ..., 0.330741, 0.002619, 0.005043, 0.037773],\n",
              "       [0.111036, 0.060999, 0.134507, 0.118398, ..., 0.330741, 0.002619, 0.005043, 0.037773],\n",
              "       [0.111036, 0.060999, 0.134507, 0.118398, ..., 0.330741, 0.002619, 0.005043, 0.037773],\n",
              "       [0.111036, 0.060999, 0.134507, 0.118398, ..., 0.330741, 0.002619, 0.005043, 0.037773]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "83Kn_g_5NWfw",
        "outputId": "d54d04a7-430c-488f-fd6f-82f68a9dcabc"
      },
      "source": [
        "#Evaluating Model Performance by creating confusion matrix and classification report\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "print('Confusion Matrix')\n",
        "print(confusion_matrix(y_pred, df_test['label']))\n",
        "print('Classification Report')\n",
        "print(classification_report(y_pred, df_test['label']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix\n",
            "[[ 0  0  0  0 ...  0  0  0  0]\n",
            " [ 0  0  0  0 ...  0  0  0  0]\n",
            " [ 0  0  0  0 ...  0  0  0  0]\n",
            " [ 0  0  0  0 ...  0  0  0  0]\n",
            " ...\n",
            " [ 0  0  0  0 ...  0  0  0  0]\n",
            " [26 17 30 10 ...  2 83  3  7]\n",
            " [ 0  0  0  0 ...  0  0  0  0]\n",
            " [ 0  0  0  0 ...  0  0  0  0]]\n",
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         0\n",
            "           1       0.00      0.00      0.00         0\n",
            "           2       0.00      0.00      0.00         0\n",
            "           3       0.00      0.00      0.00         0\n",
            "           4       0.00      0.00      0.00         0\n",
            "           5       0.00      0.00      0.00         0\n",
            "           6       1.00      0.41      0.58       202\n",
            "           8       0.00      0.00      0.00         0\n",
            "           9       0.00      0.00      0.00         0\n",
            "\n",
            "    accuracy                           0.41       202\n",
            "   macro avg       0.11      0.05      0.06       202\n",
            "weighted avg       1.00      0.41      0.58       202\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HdhotqlwNrdZ",
        "outputId": "2ead4ee3-f8cb-456e-8bf4-ccf4d29bc8c4"
      },
      "source": [
        "mat = confusion_matrix(y_pred, df_test['label'])\n",
        "\n",
        "diag = np.diagonal(mat)\n",
        "print('No of correctly identified labels :',sum(diag))\n",
        "print('No of misclassified samples : ',sum(sum(mat))-sum(diag))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No of correctly identified labels : 83\n",
            "No of misclassified samples :  119\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qnkhEoLUNrgL",
        "outputId": "0e7f7ba0-6128-4cd5-801c-2989ac210fc5"
      },
      "source": [
        "tr_emb.shape[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30891"
            ]
          },
          "metadata": {},
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FeJSU2tbNrjd",
        "outputId": "246461ce-7006-4a13-f7cf-08f2394e24b6"
      },
      "source": [
        "tr_emb.shape[1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "768"
            ]
          },
          "metadata": {},
          "execution_count": 146
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HyGh48ltNrrC"
      },
      "source": [
        "from keras.layers import Layer\n",
        "import keras.backend as K"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nzvrukfGNrtv"
      },
      "source": [
        "class attention(Layer):\n",
        "    def __init__(self,**kwargs):\n",
        "        super(attention,self).__init__(**kwargs)\n",
        "\n",
        "    def build(self,input_shape):\n",
        "        self.W=self.add_weight(name=\"att_weight\",shape=(input_shape[-1],1),initializer=\"normal\")\n",
        "        self.b=self.add_weight(name=\"att_bias\",shape=(input_shape[1],1),initializer=\"zeros\")        \n",
        "        super(attention, self).build(input_shape)\n",
        "\n",
        "    def call(self,x):\n",
        "        et=K.squeeze(K.tanh(K.dot(x,self.W)+self.b),axis=-1)\n",
        "        at=K.softmax(et)\n",
        "        at=K.expand_dims(at,axis=-1)\n",
        "        output=x*at\n",
        "        return K.sum(output,axis=1)\n",
        "\n",
        "    def compute_output_shape(self,input_shape):\n",
        "        return (input_shape[0],input_shape[-1])\n",
        "\n",
        "    def get_config(self):\n",
        "        return super(attention,self).get_config()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "id": "s0ByUwWTCMGI",
        "outputId": "b8201c7d-00e4-47ab-cb5e-897211ae5b96"
      },
      "source": [
        "from keras import layers\n",
        "from keras.layers import Embedding, Dense, Input, concatenate, Layer, Lambda, Dropout, Activation\n",
        "from keras.models import Sequential, Model\n",
        "text_input = Input(shape=(None,768,), dtype='float32', name='text')\n",
        "\n",
        "l_mask = layers.Masking(mask_value=-99.)(text_input)\n",
        "# Which we encoded in a single vector via a LSTM\n",
        "encoded_text = layers.LSTM(100,return_sequences=True)(l_mask)\n",
        "att_out=attention()(encoded_text)\n",
        "out_dense = layers.Dense(30, activation='relu')(att_out)\n",
        "# # And we add a softmax classifier on top\n",
        "out = layers.Dense(len(label_list), activation='softmax')(out_dense)\n",
        "# At model instantiation, we specify the input and the output:\n",
        "model = Model(text_input, out)\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['acc'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mzeros\u001b[0;34m(shape, dtype, name)\u001b[0m\n\u001b[1;32m   2969\u001b[0m         shape = constant_op._tensor_shape_tensor_conversion_function(\n\u001b[0;32m-> 2970\u001b[0;31m             tensor_shape.TensorShape(shape))\n\u001b[0m\u001b[1;32m   2971\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnimplementedError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_tensor_shape_tensor_conversion_function\u001b[0;34m(s, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    362\u001b[0m     raise ValueError(\n\u001b[0;32m--> 363\u001b[0;31m         \"Cannot convert a partially known TensorShape to a Tensor: %s\" % s)\n\u001b[0m\u001b[1;32m    364\u001b[0m   \u001b[0ms_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Cannot convert a partially known TensorShape to a Tensor: (?, 1)",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-143-8d3347846bfb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Which we encoded in a single vector via a LSTM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mencoded_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreturn_sequences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0matt_out\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mout_dense\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0matt_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# # And we add a softmax classifier on top\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer_v1.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    743\u001b[0m           \u001b[0;31m# Build layer if applicable (if the `build` method has been\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    744\u001b[0m           \u001b[0;31m# overridden).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 745\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    746\u001b[0m           \u001b[0mcast_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    747\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer_v1.py\u001b[0m in \u001b[0;36m_maybe_build\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2066\u001b[0m         \u001b[0;31m# operations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2067\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaybe_init_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2068\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2069\u001b[0m       \u001b[0;31m# We must set also ensure that the layer is marked as built, and the build\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2070\u001b[0m       \u001b[0;31m# shape is stored since user defined build functions may not be calling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-137-b351120b7e02>\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"att_weight\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minitializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"normal\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"att_bias\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minitializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"zeros\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer_v1.py\u001b[0m in \u001b[0;36madd_weight\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, trainable, constraint, partitioner, use_resource, synchronization, aggregation, **kwargs)\u001b[0m\n\u001b[1;32m    438\u001b[0m         \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m         \u001b[0maggregation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m         caching_device=caching_device)\n\u001b[0m\u001b[1;32m    441\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mregularizer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m       \u001b[0;31m# TODO(fchollet): in the future, this should be handled at the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_add_variable_with_custom_getter\u001b[0;34m(self, name, shape, dtype, initializer, getter, overwrite, **kwargs_for_getter)\u001b[0m\n\u001b[1;32m    816\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0minitializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 818\u001b[0;31m         **kwargs_for_getter)\n\u001b[0m\u001b[1;32m    819\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m     \u001b[0;31m# If we set an initializer and the variable processed it, tracking will not\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer_utils.py\u001b[0m in \u001b[0;36mmake_variable\u001b[0;34m(name, shape, dtype, initializer, trainable, caching_device, validate_shape, constraint, use_resource, collections, synchronization, aggregation, partitioner)\u001b[0m\n\u001b[1;32m    127\u001b[0m       \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m       \u001b[0maggregation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m       shape=variable_shape if variable_shape else None)\n\u001b[0m\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    264\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mVariableV1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_v1_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_v2_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m_variable_v1_call\u001b[0;34m(cls, initial_value, trainable, collections, validate_shape, caching_device, name, variable_def, dtype, expected_shape, import_scope, constraint, use_resource, synchronization, aggregation, shape)\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0maggregation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m         shape=shape)\n\u001b[0m\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m   def _variable_v2_call(cls,\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    203\u001b[0m                         shape=None):\n\u001b[1;32m    204\u001b[0m     \u001b[0;34m\"\"\"Call on Variable class. Useful to force the signature.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m     \u001b[0mprevious_getter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdefault_variable_creator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgetter\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creator_stack\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m       \u001b[0mprevious_getter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_make_getter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprevious_getter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mdefault_variable_creator\u001b[0;34m(next_creator, **kwargs)\u001b[0m\n\u001b[1;32m   2624\u001b[0m         \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2625\u001b[0m         \u001b[0maggregation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2626\u001b[0;31m         shape=shape)\n\u001b[0m\u001b[1;32m   2627\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2628\u001b[0m     return variables.RefVariable(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    268\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_v2_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVariableMetaclass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, initial_value, trainable, collections, validate_shape, caching_device, name, dtype, variable_def, import_scope, constraint, distribute_strategy, synchronization, aggregation, shape)\u001b[0m\n\u001b[1;32m   1611\u001b[0m           \u001b[0maggregation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1612\u001b[0m           \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1613\u001b[0;31m           distribute_strategy=distribute_strategy)\n\u001b[0m\u001b[1;32m   1614\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1615\u001b[0m   def _init_from_args(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36m_init_from_args\u001b[0;34m(self, initial_value, trainable, collections, caching_device, name, dtype, constraint, synchronization, aggregation, distribute_strategy, shape)\u001b[0m\n\u001b[1;32m   1738\u001b[0m           \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Initializer\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_context_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1739\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0minit_from_fn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1740\u001b[0;31m               \u001b[0minitial_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitial_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1741\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitial_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrackable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCheckpointInitialValue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1742\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_initialize_trackable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/init_ops.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, shape, dtype, partition_info)\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   2913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2914\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2915\u001b[0;31m     \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2916\u001b[0m     \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_zeros_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2917\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mzeros\u001b[0;34m(shape, dtype, name)\u001b[0m\n\u001b[1;32m   2971\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnimplementedError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2972\u001b[0m         \u001b[0;31m# Happens when shape is a list with tensor elements\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2973\u001b[0;31m         \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2974\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shape_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2975\u001b[0m       \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Ensure it's a vector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/profiler/trace.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtrace_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1565\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1566\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1567\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1568\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    344\u001b[0m                                          as_ref=False):\n\u001b[1;32m    345\u001b[0m   \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    270\u001b[0m   \"\"\"\n\u001b[1;32m    271\u001b[0m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0;32m--> 272\u001b[0;31m                         allow_broadcast=True)\n\u001b[0m\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    288\u001b[0m       tensor_util.make_tensor_proto(\n\u001b[1;32m    289\u001b[0m           \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverify_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 290\u001b[0;31m           allow_broadcast=allow_broadcast))\n\u001b[0m\u001b[1;32m    291\u001b[0m   \u001b[0mdtype_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattr_value_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAttrValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m   \u001b[0mattrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"value\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtensor_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"dtype\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdtype_value\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/tensor_util.py\u001b[0m in \u001b[0;36mmake_tensor_proto\u001b[0;34m(values, dtype, shape, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m       \u001b[0m_AssertCompatible\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m       \u001b[0mnparray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp_dt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m       \u001b[0;31m# check to them.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m       \u001b[0;31m# We need to pass in quantized values as tuples, so don't apply the shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: __int__ returned non-int (type NoneType)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_aPkDUmbCHnf"
      },
      "source": [
        "att_in=LSTM(no_of_neurons,return_sequences=True,dropout=0.3,recurrent_dropout=0.2)(x)\n",
        "att_out=attention()(att_in)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JbYyvJod6O5W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4029ea2c-e691-4c95-8b05-a70d2c7bcefb"
      },
      "source": [
        "# from keras import layers\n",
        "# from keras.layers import Embedding, Dense, Input, concatenate, Layer, Lambda, Dropout, Activation\n",
        "# from keras.models import Sequential, Model\n",
        "# text_input = Input(shape=(None,768,), dtype='float32', name='text')\n",
        "\n",
        "# l_mask = layers.Masking(mask_value=-99.)(text_input)\n",
        "# # Which we encoded in a single vector via a LSTM\n",
        "# encoded_text = layers.LSTM(100,)(l_mask)\n",
        "# out_dense = layers.Dense(30, activation='relu')(encoded_text)\n",
        "# # And we add a softmax classifier on top\n",
        "# out = layers.Dense(len(label_list), activation='softmax')(out_dense)\n",
        "# # At model instantiation, we specify the input and the output:\n",
        "# model = Model(text_input, out)\n",
        "# model.compile(optimizer='adam',\n",
        "#               loss='sparse_categorical_crossentropy',\n",
        "#               metrics=['acc'])\n",
        "# model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "text (InputLayer)            [(None, None, 768)]       0         \n",
            "_________________________________________________________________\n",
            "masking (Masking)            (None, None, 768)         0         \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 100)               347600    \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 30)                3030      \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                310       \n",
            "=================================================================\n",
            "Total params: 350,940\n",
            "Trainable params: 350,940\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxp8kZnR6O8H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "592f0484-7483-45bd-c106-113667e8a7f3"
      },
      "source": [
        "df_train.shape, df_val.shape, df_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((13552, 3), (3388, 3), (202, 3))"
            ]
          },
          "metadata": {},
          "execution_count": 183
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "akL-NEMh6O_J"
      },
      "source": [
        "num_sequences = len(df_train['mean_emb'].to_list())\n",
        "batch_size = 4\n",
        "batches_per_epoch =  3388\n",
        "assert batch_size * batches_per_epoch == num_sequences\n",
        "num_features= 768\n",
        "def train_generator(df):\n",
        "    x_list= df['mean_emb'].to_list()\n",
        "    y_list =  df.label.to_list()\n",
        "    # Generate batches\n",
        "    while True:\n",
        "        for b in range(batches_per_epoch):\n",
        "            longest_index = (b + 1) * batch_size - 1\n",
        "            timesteps = len(max(df['mean_emb'].to_list()[:(b + 1) * batch_size][-batch_size:], key=len))\n",
        "            x_train = np.full((batch_size, timesteps, num_features), -99.)\n",
        "            y_train = np.zeros((batch_size,  1))\n",
        "            for i in range(batch_size):\n",
        "                li = b * batch_size + i\n",
        "                x_train[i, 0:len(x_list[li]), :] = x_list[li]\n",
        "                y_train[i] = y_list[li]\n",
        "            print(x_train.shape , y_train.shape)\n",
        "            yield x_train, y_train\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AV-9Le5i6PCE"
      },
      "source": [
        "num_sequences_val = len(df_val['mean_emb'].to_list())\n",
        "batch_size_val = 4\n",
        "batches_per_epoch_val = 847\n",
        "assert batch_size_val * batches_per_epoch_val == num_sequences_val\n",
        "num_features= 768\n",
        "def val_generator(df):\n",
        "    x_list= df['mean_emb'].to_list()\n",
        "    y_list =  df.label.to_list()\n",
        "    # Generate batches\n",
        "    while True:\n",
        "        for b in range(batches_per_epoch_val):\n",
        "            longest_index = (b + 1) * batch_size_val - 1\n",
        "            timesteps = len(max(df['mean_emb'].to_list()[:(b + 1) * batch_size_val][-31:], key=len))\n",
        "            # print(len(df_train['emb'].to_list()[:b+batch_size][-7:]))\n",
        "            x_train = np.full((batch_size_val, timesteps, num_features), -99.)\n",
        "            y_train = np.zeros((batch_size_val,  1))\n",
        "            for i in range(batch_size_val):\n",
        "                li = b * batch_size_val + i\n",
        "                # print(\"li\", li)\n",
        "                # print(x_train[i, 0:len(x_list[li]), :].shape, len(x_list[li]))\n",
        "                x_train[i, 0:len(x_list[li]), :] = x_list[li]\n",
        "                y_train[i] = y_list[li]\n",
        "            yield x_train, y_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4L_65gSD6esK"
      },
      "source": [
        "from keras.callbacks import ReduceLROnPlateau\n",
        "call_reduce = ReduceLROnPlateau(monitor='val_acc', factor=0.95, patience=3, verbose=2,\n",
        "                                mode='auto', min_delta=0.01, cooldown=0, min_lr=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YoKi1cTn6evg",
        "outputId": "b607b89e-03c0-4118-ab12-93765b663e27"
      },
      "source": [
        "model.fit_generator(train_generator(df_train), steps_per_epoch=batches_per_epoch, epochs=10,\n",
        "                    validation_data=val_generator(df_val), validation_steps=batches_per_epoch_val, callbacks =[call_reduce] )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training_v1.py:1228: UserWarning: `model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`model.fit_generator` is deprecated and '\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "3388/3388 [==============================] - ETA: 0s - batch: 1693.5000 - size: 4.0000 - loss: 0.3541 - acc: 0.9072"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:2470: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3388/3388 [==============================] - 2049s 605ms/step - batch: 1693.5000 - size: 4.0000 - loss: 0.3541 - acc: 0.9072 - val_loss: 0.3301 - val_acc: 0.9126 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "3388/3388 [==============================] - 2049s 605ms/step - batch: 1693.5000 - size: 4.0000 - loss: 0.3271 - acc: 0.9125 - val_loss: 0.3262 - val_acc: 0.9112 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "3388/3388 [==============================] - 2054s 606ms/step - batch: 1693.5000 - size: 4.0000 - loss: 0.3190 - acc: 0.9131 - val_loss: 0.3220 - val_acc: 0.9171 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "3388/3388 [==============================] - ETA: 0s - batch: 1693.5000 - size: 4.0000 - loss: 0.3145 - acc: 0.9147\n",
            "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.0009500000451225787.\n",
            "3388/3388 [==============================] - 2049s 605ms/step - batch: 1693.5000 - size: 4.0000 - loss: 0.3145 - acc: 0.9147 - val_loss: 0.3236 - val_acc: 0.9100 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "3388/3388 [==============================] - 2054s 606ms/step - batch: 1693.5000 - size: 4.0000 - loss: 0.3064 - acc: 0.9147 - val_loss: 0.3194 - val_acc: 0.9159 - lr: 9.5000e-04\n",
            "Epoch 6/10\n",
            "3388/3388 [==============================] - 2047s 604ms/step - batch: 1693.5000 - size: 4.0000 - loss: 0.2991 - acc: 0.9164 - val_loss: 0.3195 - val_acc: 0.9120 - lr: 9.5000e-04\n",
            "Epoch 7/10\n",
            "3388/3388 [==============================] - ETA: 0s - batch: 1693.5000 - size: 4.0000 - loss: 0.2982 - acc: 0.9159\n",
            "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0009025000152178108.\n",
            "3388/3388 [==============================] - 2049s 605ms/step - batch: 1693.5000 - size: 4.0000 - loss: 0.2982 - acc: 0.9159 - val_loss: 0.3107 - val_acc: 0.9171 - lr: 9.5000e-04\n",
            "Epoch 8/10\n",
            "3388/3388 [==============================] - 2054s 606ms/step - batch: 1693.5000 - size: 4.0000 - loss: 0.2947 - acc: 0.9174 - val_loss: 0.3118 - val_acc: 0.9117 - lr: 9.0250e-04\n",
            "Epoch 9/10\n",
            "3388/3388 [==============================] - 2069s 611ms/step - batch: 1693.5000 - size: 4.0000 - loss: 0.2910 - acc: 0.9187 - val_loss: 0.3166 - val_acc: 0.9129 - lr: 9.0250e-04\n",
            "Epoch 10/10\n",
            "3388/3388 [==============================] - ETA: 0s - batch: 1693.5000 - size: 4.0000 - loss: 0.2885 - acc: 0.9195\n",
            "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.0008573750033974647.\n",
            "3388/3388 [==============================] - 2072s 612ms/step - batch: 1693.5000 - size: 4.0000 - loss: 0.2885 - acc: 0.9195 - val_loss: 0.3135 - val_acc: 0.9150 - lr: 9.0250e-04\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f641390f550>"
            ]
          },
          "metadata": {},
          "execution_count": 187
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5EjU_PJ-6eyT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51b2aa06-c5a9-47f8-9d09-d0f62724d46e"
      },
      "source": [
        "num_sequences_val = len(df_test['mean_emb'].to_list())\n",
        "batch_size_val = 2\n",
        "batches_per_epoch_val = 101\n",
        "assert batch_size_val * batches_per_epoch_val == num_sequences_val\n",
        "num_features= 768\n",
        "model.evaluate_generator(val_generator(df_test), steps= batches_per_epoch_val)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training_v1.py:1261: UserWarning: `Model.evaluate_generator` is deprecated and will be removed in a future version. Please use `Model.evaluate`, which supports generators.\n",
            "  warnings.warn('`Model.evaluate_generator` is deprecated and '\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.2631700588482441, 0.9059406]"
            ]
          },
          "metadata": {},
          "execution_count": 188
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88KjGuTc9u-s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32b1d967-12f6-49fd-8024-1c1e25ef2404"
      },
      "source": [
        "num_sequences_val = len(df_test['mean_emb'].to_list())\n",
        "batch_size_val = 2\n",
        "batches_per_epoch_val = 101\n",
        "assert batch_size_val * batches_per_epoch_val == num_sequences_val\n",
        "num_features= 768\n",
        "y_proba=model.predict(val_generator(df_test), steps= batches_per_epoch_val)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:2470: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vbya2kLw9yID"
      },
      "source": [
        "y_pred=[]\n",
        "for i in y_proba:\n",
        "    max_index_row = np.argmax(i, axis=0)\n",
        "    y_pred.append(max_index_row)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hazn-52090JH",
        "outputId": "2fa9c9f7-dd90-4360-d175-af158b8c2cd0"
      },
      "source": [
        "#Evaluating Model Performance by creating confusion matrix and classification report\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "print('Confusion Matrix')\n",
        "print(confusion_matrix(y_pred, df_test['label']))\n",
        "print('Classification Report')\n",
        "print(classification_report(y_pred, df_test['label']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix\n",
            "[[23  1  4  0 ...  1  1  1  0]\n",
            " [ 0 14  0  0 ...  0  0  1  0]\n",
            " [ 2  1 24  0 ...  0  0  0  0]\n",
            " [ 0  0  0  9 ...  0  0  0  0]\n",
            " ...\n",
            " [ 1  0  0  0 ...  1  0  0  0]\n",
            " [ 0  1  0  0 ...  0 82  0  0]\n",
            " [ 0  0  0  0 ...  0  0  1  0]\n",
            " [ 0  0  0  0 ...  0  0  0  7]]\n",
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.72      0.79        32\n",
            "           1       0.82      0.88      0.85        16\n",
            "           2       0.80      0.89      0.84        27\n",
            "           3       0.90      1.00      0.95         9\n",
            "           4       0.92      0.88      0.90        25\n",
            "           5       0.50      0.50      0.50         2\n",
            "           6       0.99      0.99      0.99        83\n",
            "           8       0.33      1.00      0.50         1\n",
            "           9       1.00      1.00      1.00         7\n",
            "\n",
            "    accuracy                           0.91       202\n",
            "   macro avg       0.79      0.87      0.81       202\n",
            "weighted avg       0.91      0.91      0.91       202\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PkFTwbUdcRFB"
      },
      "source": [
        "mat = confusion_matrix(y_pred, df_test['label'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pFWFYexOcTim",
        "outputId": "4ddd4351-efa9-43d7-bbe9-246664b8c4ef"
      },
      "source": [
        "print(mat)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[23  1  4  0 ...  1  1  1  0]\n",
            " [ 0 14  0  0 ...  0  0  1  0]\n",
            " [ 2  1 24  0 ...  0  0  0  0]\n",
            " [ 0  0  0  9 ...  0  0  0  0]\n",
            " ...\n",
            " [ 1  0  0  0 ...  1  0  0  0]\n",
            " [ 0  1  0  0 ...  0 82  0  0]\n",
            " [ 0  0  0  0 ...  0  0  1  0]\n",
            " [ 0  0  0  0 ...  0  0  0  7]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W7-B1E8PbK8L",
        "outputId": "6f752fc8-e0ee-47ae-d953-fcec8c197e70"
      },
      "source": [
        "diag = np.diagonal(mat)\n",
        "sum(diag)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "183"
            ]
          },
          "metadata": {},
          "execution_count": 194
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eSp_J7dpcLAF",
        "outputId": "2b9f343f-e674-40ef-ffdd-25b8beb9123f"
      },
      "source": [
        "sum(sum(mat))-sum(diag)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "19"
            ]
          },
          "metadata": {},
          "execution_count": 195
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I_zCQnzGW99s",
        "outputId": "7f0bf4db-0d3c-440d-d70e-467359adda1e"
      },
      "source": [
        "#Just for reference -->DO NOT RUN IT\n",
        "# #BERT: Fine Tuning Training & Evaluating\n",
        "# print(f'Beginning Training!')\n",
        "# #current_time = datetime.time()\n",
        "# estimator.train(input_fn=train_input_fn, max_steps=num_train_steps)\n",
        "# #print(\"Training took time \", datetime.now() - current_time)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Beginning Training!\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done calling model_fn.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done calling model_fn.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Create CheckpointSaverHook.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Create CheckpointSaverHook.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Graph was finalized.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Graph was finalized.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Running local_init_op.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Running local_init_op.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done running local_init_op.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done running local_init_op.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 0 into /content/drive/MyDrive/MS_Final_Project/Model_checkpoints_CC/model.ckpt.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 0 into /content/drive/MyDrive/MS_Final_Project/Model_checkpoints_CC/model.ckpt.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 2.269146, step = 0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 2.269146, step = 0\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 2.03454\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 2.03454\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 1.0293264, step = 100 (49.153 sec)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 1.0293264, step = 100 (49.153 sec)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 2.47521\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 2.47521\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 1.0047464, step = 200 (40.401 sec)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 1.0047464, step = 200 (40.401 sec)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 300...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 300...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 300 into /content/drive/MyDrive/MS_Final_Project/Model_checkpoints_CC/model.ckpt.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 300 into /content/drive/MyDrive/MS_Final_Project/Model_checkpoints_CC/model.ckpt.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 300...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 300...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 2.14739\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 2.14739\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.8332013, step = 300 (46.568 sec)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.8332013, step = 300 (46.568 sec)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 2.47347\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 2.47347\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 1.0196545, step = 400 (40.429 sec)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 1.0196545, step = 400 (40.429 sec)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 2.47606\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 2.47606\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.5582099, step = 500 (40.387 sec)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.5582099, step = 500 (40.387 sec)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 600...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 600...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 600 into /content/drive/MyDrive/MS_Final_Project/Model_checkpoints_CC/model.ckpt.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 600 into /content/drive/MyDrive/MS_Final_Project/Model_checkpoints_CC/model.ckpt.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 600...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 600...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 2.16216\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 2.16216\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.70514524, step = 600 (46.250 sec)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.70514524, step = 600 (46.250 sec)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 2.47374\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 2.47374\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 1.2256243, step = 700 (40.425 sec)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 1.2256243, step = 700 (40.425 sec)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 2.47581\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 2.47581\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.23693301, step = 800 (40.391 sec)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.23693301, step = 800 (40.391 sec)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 900...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 900...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 900 into /content/drive/MyDrive/MS_Final_Project/Model_checkpoints_CC/model.ckpt.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 900 into /content/drive/MyDrive/MS_Final_Project/Model_checkpoints_CC/model.ckpt.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 900...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 900...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 2.13953\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 2.13953\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 1.0314894, step = 900 (46.739 sec)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 1.0314894, step = 900 (46.739 sec)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 2.47311\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 2.47311\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.50885725, step = 1000 (40.436 sec)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.50885725, step = 1000 (40.436 sec)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 2.47567\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 2.47567\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.3976738, step = 1100 (40.393 sec)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.3976738, step = 1100 (40.393 sec)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 1200...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 1200...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 1200 into /content/drive/MyDrive/MS_Final_Project/Model_checkpoints_CC/model.ckpt.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 1200 into /content/drive/MyDrive/MS_Final_Project/Model_checkpoints_CC/model.ckpt.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 1200...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 1200...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 2.14793\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 2.14793\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.48501277, step = 1200 (46.556 sec)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.48501277, step = 1200 (46.556 sec)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 2.47377\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 2.47377\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.2039797, step = 1300 (40.424 sec)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.2039797, step = 1300 (40.424 sec)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 2.47695\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 2.47695\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.35457504, step = 1400 (40.372 sec)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.35457504, step = 1400 (40.372 sec)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 1500...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 1500...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 1500 into /content/drive/MyDrive/MS_Final_Project/Model_checkpoints_CC/model.ckpt.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 1500 into /content/drive/MyDrive/MS_Final_Project/Model_checkpoints_CC/model.ckpt.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/training/saver.py:971: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to delete files with this prefix.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/training/saver.py:971: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to delete files with this prefix.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 1500...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 1500...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 2.08047\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 2.08047\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.5878937, step = 1500 (48.067 sec)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.5878937, step = 1500 (48.067 sec)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 2.47501\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 2.47501\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.3608415, step = 1600 (40.403 sec)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.3608415, step = 1600 (40.403 sec)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 2.47714\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 2.47714\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.36334234, step = 1700 (40.369 sec)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.36334234, step = 1700 (40.369 sec)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 1800...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 1800...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 1800 into /content/drive/MyDrive/MS_Final_Project/Model_checkpoints_CC/model.ckpt.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 1800 into /content/drive/MyDrive/MS_Final_Project/Model_checkpoints_CC/model.ckpt.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 1800...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 1800...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 2.15762\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 2.15762\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.2758512, step = 1800 (46.347 sec)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.2758512, step = 1800 (46.347 sec)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 2.47499\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 2.47499\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.64759105, step = 1900 (40.404 sec)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.64759105, step = 1900 (40.404 sec)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 1982...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 1982...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 1982 into /content/drive/MyDrive/MS_Final_Project/Model_checkpoints_CC/model.ckpt.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 1982 into /content/drive/MyDrive/MS_Final_Project/Model_checkpoints_CC/model.ckpt.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 1982...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 1982...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Loss for final step: 0.43535817.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Loss for final step: 0.43535817.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<tensorflow_estimator.python.estimator.estimator.EstimatorV2 at 0x7ff929b52290>"
            ]
          },
          "execution_count": 112,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CiXD_1uTFCwc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}